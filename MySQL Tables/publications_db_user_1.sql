-- MySQL dump 10.13  Distrib 8.0.27, for Win64 (x86_64)
--
-- Host: 127.0.0.1    Database: publications_db
-- ------------------------------------------------------
-- Server version	5.7.37-log

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `user_1`
--

DROP TABLE IF EXISTS `user_1`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `user_1` (
  `ID` int(11) DEFAULT NULL,
  `NAME` text,
  `LINK` text,
  `ABSTRACT` text
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `user_1`
--

LOCK TABLES `user_1` WRITE;
/*!40000 ALTER TABLE `user_1` DISABLE KEYS */;
INSERT INTO `user_1` VALUES (1,'Ku-Mahamud, Ku Ruhana','https://www.scopus.com/authid/detail.uri?authorId=55907349500','Multi-objective swarm intelligence (MOSI) metaheuristics were proposed to solve multi-objective optimization problems (MOPs) that consist of two or more conflict objectives, in which improving an objective leads to the degradation of the other. The MOSI algorithms were based on the integration of single objective algorithms and multi-objective optimization (MOO) approaches. The MOO approaches included scalarization, Pareto dominance, decomposition, and indicator-based. In this paper, the status of MOO research and state-of-the-art MOSI algorithms, namely multi-objective particle swarm,artificialbeecolony,fireflyalgorithm,batalgorithm,gravitational search algorithm, grey wolf optimizer, bacterial foraging, and moth-flame optimization algorithms, were reviewed. These reviewed algorithms were mainly developed to solve continuous MOPs. The review was based on how the algorithms dealt with objective functions using MOO approaches, the benchmark MOPs used in the evaluation and performance metrics. Furthermore, it described the advantages and disadvantages of each MOO approach and provides some possible future research directions in this area. The results showed that several MOO approaches were used in most of the proposed MOSI algorithms. Integrating other different MOO approaches might help in developing more effective optimization algorithms, especially in solving complex MOPs. Furthermore, most of the MOSI algorithms were evaluated using MOPs with two objectives, which clarified open issues in this research area. Ant-tree-miner (ATM) has an advantage over the conventional decision tree algorithm in terms of feature selection. However, real world applications commonly involved imbalanced class problem where the classes have different importance. This condition impeded the entropy-based heuristic of existing ATM algorithm to develop effective decision boundaries due to its biasness towards the dominant class. Consequently, the induced decision trees are dominated by the majority class which lack in predictive ability on the rare class. This study proposed an enhanced algorithm called Hellinger-Ant-tree-miner (HATM) which is inspired by ant colony optimization (ACO) metaheuristic for imbalanced learning using decision tree classification algorithm. The proposed algorithm was compared to the existing algorithm, ATM in nine (9) publicly available imbalanced data sets. Simulation study reveals the superiority of HATM when the sample size increases with skewed class (Imbalanced Ratio < 50%). Experimental results demonstrate the performance of the existing algorithm measured by BACC has been improved due to the class skew-insensitiveness of Hellinger Distance. The statistical significance test shows that HATM has higher mean BACC score than ATM. Ant colony optimization (ACO) is a well-known algorithm from swarm intelligence that plays an essential role in obtaining rich solutions to complex problems with wide search space. ACO is successfully applied to different application problems involving rules-based classification through an ant-miner classifier. However, in the ant-miner classifier, rule-pruning suffers from the problem of nesting effect origins from the method of greedy Sequential Backward Selection (SBS) in term selection, thereby depriving the opportunity of obtaining a good pruned rule by adding/removing the terms during the pruning process. This paper presents an extension to the Ant-Miner, namely the genetic algorithm Ant-Miner (GA-Ant Miner), which incorporates the use of GA as a key aspect in the design and implementation of a new rule pruning technique. This pruning technique consists of three fundamental procedures: an initial population Ant-Miner, crossover to prune the rule, and mutation to diversify the pruned classification rule. The GA-Ant Miner performance is tested and compared with the most related ant-mining classifiers, including the original Ant-Miner, ACO/ PSO2, TACO-Miner, CAnt-Miner, and Ant-Miner with a hybrid pruner, across various public available UCI datasets. These datasets are varied in terms of instance number, feature size, class number, and the application domains. Overall, the performance results indicate that the GA-Ant Miner classifier outperforms the other five classifiers in the classification accuracy and model size. Furthermore, the experimental results using statistical test prove that GA-Ant Miner is the best classifier when considering the multi objectives (i.e., accuracy and model size ranks).'),(2,'Suhaidi, Hassan','https://www.scopus.com/authid/detail.uri?authorId=7201619505','The future Internet, known as Information-Centric Networking (ICN), is a realistic solution to content delivery between the content request generators (subscribers) and the server (publisher) in the Internet of Things (IoT) environment due to caching contents by in-network nodes. However, significant redundant copies of contents can be cached in this kind of network which, besides numerous advantages, introduces some undesirable features, such as security issues, content redundancy, access control, and cache overflow among others. ICN has different modules, such as mobility, routing, and caching, which are utmost important for the IoT network due to the nature of energy-constrained IoT devices. While numerous attempts are presently being made to institutionalize this emerging paradigm, careful considerations are needed to caching module at the early stage of this architecture. This is important instead of holding up until the innovation gets used and experienced. In this article, we first list some of the important features and limitations of the ICN-based IoT caching and then propose an ICN caching strategy that fits well in the energy efficient and secure IoT environment. The proposed strategy is simulated and compared with the ProbCache mechanism with regards to energy consumption and bandwidth utilization. Preliminary experimental analyses demonstrate that the proposed strategy produces better results than the ProbCache as long as the cache size of network nodes is increased. The massive number of peers in network with the mobility of peers rises the challenges of finding the best peer to establish a Device-to-Device (D2D) connection. This paper aims to evaluate the performance of the peer selection mechanism where the peer selection mechanism is proposed using a multi-attribute decision-making technique, based on Analytic Hierarchy Process (AHP) and Hierarchical Adaptive Weighting (HAW) algorithms. It attempts to find and select the best peer to establish D2D communication when the user is moving among different cells in the network. The performance of the proposed mechanism showed better performance based on the attribute weights. Most of the services used by Internet consumers such as social network platforms, video-on-demand, on-line gaming, web Media, and IP Television which are content-centric in nature; meaning they focus on named content objects instead of being focused on the host-location. In this context, many projects around named data propose redesigning and developing the communication of Internet-based on named data. NDN (Named Data Net-working) is an ideal solution to achieve efficient data sharing and retrieval since NDN focuses on the contents themselves regardless of their sources. The focus of this survey is a unique characteristic presented by NDN; PIT (Pending Interest table). PIT is part of three fundamental data structures newly introduced in the NDN router to enable full functionality of NDN. NDN router depends on reverse paths in PIT to return back Data packets to consumers. Accordingly, the PIT may present stringent restrictions in terms of scalability, for-warding, and management. The challenging task is the design of a scalable and manageable PIT because it requires per-packet updating and controlling the impact of increasing Interest packets with the highest Interest lifetime of PIT. Therefore, this survey describes into greater detail the background and several important previous researches related to issues of PIT which is PIT management based on PIT placement, and replacement, PIT implementation as a data structure, and Adaptive Interest Life-time. Thus, would assist in defining the general framework of this survey.'),(3,'Yasear, Shaymah Akram','https://www.scopus.com/authid/detail.uri?authorId=57194554063','Multi-objective swarm intelligence (MOSI) metaheuristics were proposed to solve multi-objective optimization problems (MOPs) that consist of two or more conflict objectives, in which improving an objective leads to the degradation of the other. The MOSI algorithms were based on the integration of single objective algorithms and multi-objective optimization (MOO) approaches. The MOO approaches included scalarization, Pareto dominance, decomposition, and indicator-based. In this paper, the status of MOO research and state-of-the-art MOSI algorithms, namely multi-objective particle swarm,artificialbeecolony,fireflyalgorithm,batalgorithm,gravitational search algorithm, grey wolf optimizer, bacterial foraging, and moth-flame optimization algorithms, were reviewed. These reviewed algorithms were mainly developed to solve continuous MOPs. The review was based on how the algorithms dealt with objective functions using MOO approaches, the benchmark MOPs used in the evaluation and performance metrics. Furthermore, it described the advantages and disadvantages of each MOO approach and provides some possible future research directions in this area. The results showed that several MOO approaches were used in most of the proposed MOSI algorithms. Integrating other different MOO approaches might help in developing more effective optimization algorithms, especially in solving complex MOPs. Furthermore, most of the MOSI algorithms were evaluated using MOPs with two objectives, which clarified open issues in this research area. This paper proposes an enhanced non-dominated sorting Harris\'s hawk multi-objective optimizer (ENDSHHMO) algorithm. In the original non-dominated sorting Harris\'s hawk multi-objective optimizer (NDSHHMO) algorithm, the convergence parameter is used to control the diversification and intensification during the search process. The parameter value decreases linearly as the number of iterations of the algorithm increases. This adjustment strategy of the parameter cannot fully reflect the actual optimization search process. Therefore, an improved adjustment strategy has been proposed and integrated with the NDSHHMO algorithm. This strategy can ensure that the proposed algorithm has a better diversification and intensification ability during the optimization process and improves the convergence to the Pareto front. The performance of the proposed enhanced NDSHHMO algorithm has been evaluated using a set of well-known multi-objective optimization problems. The results of the ENDSHHMO are compared with the NDSHHMO algorithm, which shows that the proposed algorithm is superior.In this paper, a new population update strategy is proposed to overcome the limitations of the non-dominated sorting Harrisâ€™s hawk multi-objective optimizer (NDSHHMO) algorithm. In the NDSHHMO algorithm, the population of hawks is updated based on the average positions of the first three best solutions in the search space. This update strategy leads to the algorithm falling into local optima due to population diversity loss, which causes poor convergence toward the true Pareto front. The proposed population update strategy is inspired by the flush-and-ambush (FA) tactic employed by the Harrisâ€™s hawks in nature. The proposed algorithm is called non-dominated sorting Harrisâ€™s hawksâ€™ multi-objective optimizer based on the flush-and-ambush tactic (FA-NDSHHMO). The population update strategy in the FA-NDSHHMO includes two main stages, namely, updating the position of hawks using proposed flush-and-ambush movement strategy and selecting the best hawks by using a non-dominated sorting approach to be used in the next generation. The proposed population update strategy aims to improve the search ability of the algorithm, in terms of the diversity of a non-dominated solution and convergence toward the Pareto front. To evaluate the performance of the FA-NDSHHMO algorithm, a set of 10 multi-objective optimization problems has been used. The obtained results show that the new population update strategy has improved the search ability of the FA-NDSHHMO. Furthermore, the results show superiority of the FA-NDSHHMO algorithm compared to the NDSHHMO, multi-objective grasshopper and grey wolf optimization algorithms.The population of hawks in the Harris\'s hawk multi-objective optimizer (HHMO) algorithm is generated using uniform distribution random number. This method does not guarantee that the solutions can be evenly distributed in the search space of the problem, which may affect the efficiency of the algorithm. Therefore, to improve the performance of HHMO algorithm, two-steps initial population generation method is proposed. This method is developed based on R-sequence and partial opposition-based learning, which is employed to generate an initial population of hawks, with the aim to achieve better initial population. Thus better convergence toward Pareto front will be obtained. The performance of the proposed improved HHMO algorithm is evaluated using a set of well-known multi-objective optimization problems. The results of numerical simulation experiment demonstrate the effectiveness of the proposed two-step initial population generation method and showed superiority of the improved HHMO algorithm compares to the HHMO. The improved HHMO can be used to improve the convergence towards the true Pareto frontier.'),(4,'Sheik Osman, Wan Rozaini Bt','https://www.scopus.com/authid/detail.uri?authorId=57210588378','The public sector of Iraq has been struggling from a poor management of resources, infrastructure problems, the rising quantity of data, and difficulties that affect its governmental organisation\'s development, such as financial issues resulting from corruption and insecurity, the availability of IT resources, and infrastructure. Thus, cloud computing Software as a Service (CC-SaaS) can be a useful solution to help the governmental organisations to increase their service efficiency through the adoption of technology with low cost, and provide better e-services for the satisfaction of citizens as well as gain more benefit through information sharing. The adoption of CC-SaaS is not yet widespread in Iraqi public organisations due to numerous challenges, including privacy and protection, legal policy, and trust,. In the extant literature, many studies have been published that investigate the factors affecting cloud computing (CC) adoption; however, most of these studies are from developed countries. Specifically, there is a scant study that investigates the adoption of CC-SaaS, especially in unstable developing countries; hence, this makes decision-makers unclear about the ample benefits of SaaS. In fact, in countries with dangerous and conflict areas, little is known about CC-SaaS\'s adoption. Therefore, this study\'s objective is to conduct a study on the factors affecting organizational intention towards the adoption of CC-SaaS in Iraq, a country rife with conflict. Thus, it necessitates the effort to examine the effect the conflict in Iraq could contribute to the country\'s CC-SaaS adoption. Eventually, it is expected to benefit not only the public organization in Iraqi but also validates the measurements for further study. Thus, the study model was developed on the basis of TOE, DOI, and HOT, and the variables were identify based on the expert\'s opinion. Data were collected from a sample of 367 IT professionals working in six Iraqi ministries. The collected data were analyzed by using the PLS-SEM approach. The obtained results showed that the effects of technology, organisation, averment, and human variables were statistically significant. Further, External Support and Compliance with Regulation were found not supported. Nowadays, cloud computing software as a service (CC-SaaS) has gained widespread popularity and vast advantages in the information technology domain. However, the adoption rates of CC-SaaS among organisations in developing countries are inadequate and still not widely adopted. Many public organizations are still lacking a broader understanding of adopting and utilizing CC-SaaS to facilitate tasks and increase efficiency. This trend is developing countries is more evident in Iraqi public organisations; thus, it highlighted the need to adopt such technologies to be able to reduce the cost of IT infrastructure and provide fast information accessibility. This paper\'s main objective is to develop an instrument used to assess the possibilities of CC-SaaS intention to adopt more, especially in Iraqi organisations. Also, to ensure the instrument\'s validity developed to make sure they are adequate to determine the adoption and avoid the meaningless and uninterpretable experimentation result for the intention to adopt CC-SaaS in a public organization. The paper also describes a systematic approach to assess the research instrument by employing a content validity index for the proposed constructs. A panel of 12 experts was used to validate the instrument through the quantitative (content validity) method, by Item-CVI (I-CVI), Scale-level CVI (S-CVI), and the modified Kappa statistic. The result shows high content validity for the items, and it also helped reduce and modify some of the items. Thus, the results show a high level of trust in the abilities, integrity, and benevolence of CC-SaaS providers will minimize the Iraqi organization\'s security and privacy concerns and motivate them to acquire the cloud service, as technological, organisational, environmental. Human factors depicted in this paper are valid. The advancements in Cloud Computing (CC) and the creation of more bandwidth have enabled the development of a distributed and collaborative model called Software as a Service (SaaS). The CC-SaaS provides many benefits to the countries, organization, both government and private in terms of cost-saving, and quality improvement. However, the adoption of CC-SaaS is still very challenging to organizations, more especially in such instances where no specific attributes to guide user decisions on the movement into CC-SaaS. Moreover, none of the studies have provided a holistic analysis for the determinants that affect CC-SaaS adoption from user and organizational perspectives, which is certified by any expert. This paper investigates the factors affecting CC-SaaS intention to adopt in public organization, which in turn can assist organizations to gain important benefits from CC-SaaS technology. The influential factors are reviewed, selected and confirm by experts from the field of cloud computing, the results of their assessments are presented. The sophisticated improvement of Information and Communication Technology (ICT) has sparked new inventions in teaching and learning approach. These positive technological advantages therefore inspired the Malaysian Ministry of Education (MOE) to invest in digitalizing the Malaysian schools, including the implementation of Frog Virtual Learning Environments (VLE). Despite this huge investment, the ratio of usage is relatively low, especially among the teachers. This evidence indicates that there is an urgent requirement to conduct a post-implementation evaluation to investigate the factors behind the issue. Therefore, this study is conducted to develop a conceptual model based on the updated DeLone and McLean IS Success Model to evaluate the Frog VLE success among Malaysian teachers. As the study is still in the early stage, this paper will present the initial investigation that leads to the development of the conceptual model, including background of the study, the objectives, literature review and research methodology that the study wishes to employ. Based on this conceptual model, 14 hypotheses have been proposed.'),(5,'Md Dahalin, Zulkhairi','https://www.scopus.com/authid/detail.uri?authorId=23388164500','Generally, a reliable method of analysing the quality of experience is through the subjective method, which is time consuming, lacks usability, lacks repeatability in real-time and near real-time. Another method is the objective measurement that aims at predicting the subjective measurement based on the estimated mean opinion score. Therefore, this study adopted the objective measurement by implementing a quality of experience framework, which employed predictive analytics techniques to analyse the mobile internet user experience dataset gathered through the mobile network. The predictive analytics employed the use of multiple regression, neural network, decision trees, random forest, and decision forest to predict the mobile internet perceived quality of experience. Result from the study shows that decision forests perform better than other algorithms used for the predictive analytics. In addition, the result indicates that the predictive analytics can be used to enhance the allocation of network resources based on location and time constituted in the dataset. This paper presents countriesâ€™ analysis in online Services Index performance (OSI) ranking to improve Malaysia UN ranking. The study found that the top 5 countries (Spain, Saudi Arabia, Slovenia, Malta, Serbia and UAE)by-passed Malaysia the most out of 35 countries in the last 10 years. This study proposed future research to find gaps and areas for improvement while gaining insights from international best practices that have enabled other governments to surge ahead. In particular, the study found how Malaysia can improve UN ranking through investigating what those countries that by-passed Malaysia the most in the last 10 years are doing that have enabled them to offer much superior e-Government services. Community cohesion is a very broad concept which means either the process or the state in which a better relationship is established or encouraged between people of different backgrounds, not only in the physical community, but also in the virtual community. The dramatic increase in the number of social media users, especially Facebook, provides some indication that in the lives of many people, virtual community is very vital. If it can be used as a platform for nurturing or inculcating community cohesion, the benefits of virtual community can be further exploited. Somehow a model to measure community cohesion is yet to be devised. Hence, this paper aims to present the transition of the physical to virtual community cohesion model. This process began with the development of the cohesion model of the physical community. Next, the model was reviewed against the virtual community characteristics to determine its relevance for measuring virtual community cohesion. The findings suggest that of the nine physical community cohesion constructs found for the model, only eight are pertinent to virtual community. Satisfying the customersâ€™ service requirements and expectation, especially customer satisfaction had been one of the major challenges faced by the mobile network operators in most telecommunication organizations. This article implemented an analytical customer satisfaction prediction model by employing the mobile internet traffic datasets collected in real-time through the drive test measurement. To this end, the implementation phase has employed machine learning algorithms in the Microsoft Machine Learning R client Server. The results show that previous userâ€™s traffic datasets can be used to predict customer satisfaction and identify the root cause of poor customer experience before the complete deterioration of the service performance, which could lead to larger percentage of customer dissatisfaction. The mobile network operators can also use the proposed model to overcome the drawbacks of the conventional subjective method of analysing customer satisfaction.'),(6,'Kasiran, Mohd Khairudin','https://www.scopus.com/authid/detail.uri?authorId=23985300900','This paper presents countriesâ€™ analysis in online Services Index performance (OSI) ranking to improve Malaysia UN ranking. The study found that the top 5 countries (Spain, Saudi Arabia, Slovenia, Malta, Serbia and UAE)by-passed Malaysia the most out of 35 countries in the last 10 years. This study proposed future research to find gaps and areas for improvement while gaining insights from international best practices that have enabled other governments to surge ahead. In particular, the study found how Malaysia can improve UN ranking through investigating what those countries that by-passed Malaysia the most in the last 10 years are doing that have enabled them to offer much superior e-Government services. The online services index is one of three components of the United Nations e-government development index. It attempts to capture a country\'s performance in a single internationally-comparable value using a four-stage model of online service maturity. The summary of selected countries that had overtaken Malaysia in the past 10 years had been analyst. These countries (UAE, Serbia, Malta, Spain and Saudi Arabia) have the most drastic changes to their online services that overtook Malaysia in the last 10 years. This study had found gaps and areas for improvement while gaining insights from international best practices that have enabled other governments to surge ahead. The result shows that multiple languages, transaction, social media Tools, Link to Ministries, download document, facilities to check insurances coverage, single citizen log in before accessing facilities by ministry, notification of official event/new thru text and video, display statistics for visitor, provide ebook reader, display map of ministry office for visitor point of reference, provide opinion by citizen to different ministry, provide e-participation, place to display ministry publication list, smart phone application and follow up application electronically were found to effect OSI performance these five countries. This paper presents findings on a study on virtual community cohesion with the aim to determine the state of cohesion between the administrators and members of virtual community (i.e. vertical dimension). A vertical virtual community cohesion instrument from a previous study was adopted. It measures cohesion based on two constructs namely the Trust in administrators and Political participation. A survey was conducted involving 235 users of the social media. Descriptive data analysis was carried out on the respondentsâ€™ demography and perceptions with regards to the state of cohesion of the virtual community they were involved with. The overall mean scores of both constructs were found to fall into the low cohesion category, and this indicates that the state of vertical community cohesion is low. This reflects the non-political purpose of users of the social media in engaging in virtual community. However, more studies need to be carried out to confirm this. Nevertheless, both dimensions were found to be significantly influencing virtual community cohesion.'),(7,'Abu Bakar, Muhamad Shahbani','https://www.scopus.com/authid/detail.uri?authorId=36619685700','The purpose of this study is to identify the effect of Small Private Online Course (SPOC) on the studentsâ€™ achievement in chemistry subject at the pre-university level. For this purpose, three types of learning series were designed, which are Learning Series One, Learning Series Two, and Learning Series Three. Learning Series One and Learning Series Two comprised of face-to-face (F2F) learning and SPOC in a different order while Learning Series Three consists of F2F learning only. Two experimental groups and a control group involved 66 students who were studying chemistry subject at a pre-university college were randomly selected. They learned the chemical bonding topic of the subject for twelve weeks using the assigned learning series. After justifying the reliability and validity, the pre-test and post-tests for achievement have been used as research instruments for studentsâ€™ assessment of achievement in the different groups. The study outcomes show that there is a significant difference among different learning series in the achievement test scores in favour of Learning Series One, which initially implemented SPOC followed by F2F learning. Based on the results obtained, the researcher recommended that SPOC has to be introduced and widely implemented in teaching Chemistry subject at the matriculation college as it produced a positive impact on the achievement of the students. More studies have to be carried out for other subjects in the future using SPOC for the teaching and learning process as the effectiveness of the online learning has been proved by the literature. The COVID-19 outbreak is prompting many public and private universities to abruptly and comprehensively adopt online learning in place of face-to-face classes, to limit transmission of the virus. Academicians, students, and support staff are all working to accommodate this massive change. A survey research on the student, lecturer, and institutional readiness for online learning can help institutions better understand pre-COVID-19 perspectives. This study focuses on a case of Universiti Utara Malaysia (UUM) online education. This paper summary is one of a series of reports outlining higher education\'s readiness to move teaching and learning online to preserve and continue its educational mission during the current pandemic. Thus, questionnaire is distributed to all lecturers in UUM. The collected data is measured by Likert Scale of 1 to 5 and analyzed using IBM SPSSآ® software. The overall result has shown that lecturers in UUM are ready for online teaching during the lockdown period. However, there are several issues need to be rectified by the management of the university in preparing lecturer to convert their teaching and learning to online learning. As such, more training is required by the lecturer especially related to technological and online learning tools. Additionally, a reliable online learning platform is a must for the lecturer to endeavor this new experience. Ant colony optimization is a successful metaheuristic for solving combinatorial optimization problems. However, the drawback of premature exploitation arises in ant colony optimization when coupled with local searches, in which the neighborhoodâ€™s structures of the search space are not completely traversed. This paper proposes two algorithmic components for solving the premature exploitation, i.e. the reactive heuristics and recursive local search technique. The resulting algorithm is tested on two well-known combinatorial optimization problems arising in the artificial intelligence problems field and compared experimentally to six (6) variants of ACO with local search. Results showed that the enhanced algorithm outperforms the six ACO variants.'),(8,'Din, Roshidi','https://www.scopus.com/authid/detail.uri?authorId=6603619974','The enormous development in the utilization of the Internet has driven by a continuous improvement in the region of security. The enhancement of the security embedded techniques is applied to save the intellectual property. There are numerous types of security mechanisms. Steganography is the art and science of concealing secret information inside a cover media such as image, audio, video and text, without drawing any suspicion to the eavesdropper. The text is ideal for steganography due to its ubiquity. There are many steganography embedded techniques used Arabic language to embed the hidden message in the cover text. Kashida, Shifting Point and Sharp-edges are the three Arabic steganography embedded techniques with high capacity. However, these three techniques have lack of performance to embed the hidden message into the cover text. This paper present about traid-bit method by integrating these three Arabic text steganography embedded techniques. It is an effective way to evaluate many embedded techniques at the same time, and introduced one solution for various cases. The implementation of steganography in text domain is one the crutial issue that can hide an essential message to avoid the intruder. It is caused every personal information mostly in medium of text, and the steganography itself is expectedly as the solution to protect the information that is able to hide the hidden message that is unrecognized by human or machine vision. This paper concerns about one of the categories in steganography on medium of text called text steganography that specifically focus on feature-based method. This paper reviews some of previous research effort in last decade to discover the performance of technique in the development the feature-based on text steganography method. Then, ths paper also concern to discover some related performance that influences the technique and several issues in the development the feature-based on text steganography method. One of the cryptography classifications is asymmetric cryptography, which uses two different keys to encrypt and decrypt the message. This paper discusses a review of RSA scheme of asymmetric cryptography techniques. It is trying to present the domains of RSA scheme used including in public network, wireless sensor network, image encryption, cloud computing, proxy signature, Internet of Things and embedded device, based on the perspective of researchersâ€™ effort in the last decade. Other than that, this paper reviewed the trends and the performance metrics of RSA scheme such as security, speed, efficiency, computational complexity and space based on the number of researches done. Finally, the technique and strengths of the proposed scheme are also stated in this paper. Quick response (QR) code is a printed code of black and white squares that is able to store data without the use of any of the electronic devices. There are many existing researches on coloured QR code to increase the storage capacity but from time to time the storage capacity still need to be improved. This paper proposes the use of compress, multiplexing and multilayered techniques, as an integrated technique known as CoMM, to increase the storage of the existing QR code. The American Standard Code for Information Interchange (ASCII) text characters are used as an input and performance is measured by the number of characters that can be stored in a single black and white QR code version 40. The experiment metrics also include percentage of missing characters, number of produced QR code, and elapsed time to create the QR code. Simulation results indicate that the proposed algorithm stores 24 times more characters than the black and white QR code and 9 times more than other coloured QR code. Hence, this shows that the coloured QR code has the potential of becoming useful mini-data storage as it does not rely on internet connection.'),(9,'Zakaria, Nur Haryani','https://www.scopus.com/authid/detail.uri?authorId=24529316600','Cloud-based technology, which is now well established, helps in reducing costs and providing accessibility, reliability and flexibility. However, the Yemen higher educational institutions (HEIs) have not yet embraced the technology due to security and privacy concerns, lack of trust, negative cultural attitudes (i.e., tribalism), and most importantly, lack of digital devices experience in educational settings as well as lack of knowledge and technical know-how. Thus, this study proposes a conceptual model of cloud computing adoption in Yemen HEIs by investigating the influence of technology, organization and environment (TOE) factors. In addition, this study investigates the moderating effect of tribalism culture in the relationships between the identified factors and cloud computing adoption. The study employed the quantitative approach to determine the factors that influence cloud computing adoption in Yemen HEIs through a questionnaire survey. Data were collected from 328 respondents in 38 HEIs and analyzed using partial least square (PLS) structural equation modelling (SEM). The results indicate that relative advantage, reliability, compatibility, security, technology readiness, top management support, regulatory policy and competitive pressure have positive significant impacts on the cloud computing adoption, except tribalism culture with negative significant impact. The study also found that tribalism culture moderates the relationship between compatibility, reliability, security, relative advantage, regulatory policy and cloud computing adoption. This study contributes to the TOE adoption model by including the cultural factor as a moderator towards cloud computing adoption in Yemen HEIs. The study also provides a model and insights for HEIs, technology consultants, vendors and policy makers in better understanding of the factors that influence cloud computing adoption in least developed countries (LDCs), specifically, Yemen. Citations have been an acceptable journal performance metric used by many indexing databases for inclusion and discontinuation of journals in their list. Therefore, editorial teams must maintain their journal performance by increasing article citations for continuous content indexing in the databases. With this aim in hand, this study intended to assist the editorial team of the Journal of Information and Communication Technology (JICT) in increasing the performance and impact of the journal. Currently, the journal has suffered from low citation count, which may jeopardise its sustainability. Past studies in library science suggested a positive correlation between keywords and citations. Therefore, keyword and topic analyses could be a solution to address the issue of journal citation. This article described a scientometric analysis of emerging topics in general computer science, the Scopus subject area for which JICT is indexed. This study extracted bibliometric data of the top 10% journals in the subject area to create a dataset of 5,546 articles. The results of the study suggested ten emerging topics in computer science that can be considered by the journal editorial team in selecting articles and a list of highly used keywords in articles published in 2019 and 2020 (as of 15 April 2020). The outcome of this study might be considered by the JICT editorial team and other journals in general computer science that suffer from a similar issue. Refactoring techniques don\'t always improve all aspects of software quality attributes. Different types of refactoring techniques have different types of effect on different software quality attributes. consequently, software practitioners encounter challenges in selecting appropriate refactoring techniques to enhance the quality of software design in support of particular design goals. Therefore, categorization refactoring techniques depending on their influence on quality attributes is significant to enable software practitioners in improving software quality by selecting suitable refactoring techniques. A systematic review has been accomplished to determine and analyze studies which tightly related to categorize the refactoring techniques depending on their influence on quality attributes.14 primary studies have been found and selected for analysis. The obtained results showed that there is a lack of studies regarding the categorization of the refactoring techniques and the current works are insufficient to solve the challenges facing software practitioners. Several recommendations have been suggested to address these gaps. Modern mobile phones or smartphones have become a pervasive and affordable device for users at different levels of age around the world. Smartphones equipped with many useful sensors, including camera, barometer, accelerometer, and digital compass. The sensors on smartphones attracted researchers and developers to develop mobile applications (apps) and study the potential use of the sensors to support daily life activities. Unlike other types of sensor, the smartphone camera has been underutilized. Analysis of the literature suggested that smartphone camera mainly serves for personal and social photography. Practically, a smartphone camera can be used as an imaging device for reading a barcode. Although barcode has been used for identifying products and items, the use of a smartphone camera as a reading device has not been explored thoroughly. Further, scholarly resources describing the fundamental knowledge of smartphone camera barcode reading is not available in the literature which could be the reason contributed to slow research progress of the domain. Therefore, this study aims to review the current trends and future directions of smartphone camera for barcode reading. Specifically, the study reviews the literature on the types of applications that are currently available and run on the standard mobile platform for reading a barcode. It also analyzes the necessary components that made up barcode reading apps. Further, the review identifies technical and non-technical issues that are critical for the development of the apps. The contributions of this work are twofold, first, it provides the fundamental knowledge on the building blocks of camera barcode reading apps, and second, it explores the issues in the current camera barcode reading apps that could encourage exploration towards addressing the issues. Practically, the findings could spark new research ideas to address the current issues related to the use of smartphone camera for barcode reading in the near future.'),(10,'Romli, Rohaida','https://www.scopus.com/authid/detail.uri?authorId=36609124000','One of the principles in Agile is to promote sustainable development and requirements are the key point to develop sustainable software systems. One way to achieve sustainability as a software development is to make it to be the part of the product quality as a Non-Functional Requirements (NFRs). Agile Software Development (ASD) often focuses Functional Requirements (FRs) due to the nature of Agile and ignores Non-Functional Requirements (NFRs) during the process of requirement change. However, ignoring NFRs has negative impacts on software products and lack of careful consideration, increases the risk of project failure. The main objective of this article is to identify the sustainability characteristics and sub-characteristics that can be helpful to further explore the interlinked relationship of sustainable quality characteristics with managing changes in ASD to achieve software sustainability. The preliminary analysis identified sustainability characteristics such as maintainability, portability, usability, efficiency, interoperability, and reliability with their respective sub-characteristics. The identification of the sustainability characteristics sub-characteristics will serve as a first step during the process of Requirement change in ASD. Fluoroscopic images are a field of medical images that depends on the quality of image for correct diagnosis; the main trouble is the de-nosing and how to keep the poise between degradation of noisy image, from one side, and edge and fine details preservation, from the other side, especially when fluoroscopic images contain black and white type noise with high density. The previous filters could usually handle low/medium black and white type noise densities, that expense edge, =fine details preservation and fail with high density of noise that corrupts the images. Therefore, this paper proposed a new Multi-Line algorithm that deals with high-corrupted image with high density of black and white type noise. The experiments achieved images with a high quality and effectively preserved edge and fine details against black and white type noise densities depending on Peak Signal to Noise Ratio (PSNR), Mean Squared Error (MSE), and Image Enhancement Factor (IEF) measures. This paper presents the verification results of the proposed model for improving the software project-monitoring task of the Agile Kanban method (i-KAM). However, i-KAM is still in its initial phases and requires verification regarding the proposed components and associated criteria. Expert review method was used to collect valid and reliable data from experienced persons who have skills and experiences in Agile software development. There were 11 experts participated and their opinions were obtained and quantified by using descriptive analysis. Results confirm that i-KAM is a well-accepted model as it can improve the progress monitoring task in terms of extending its tracking mechanism, controlling the WIP limits, and providing useful insights on the project status. Thereafter, i-KAM was revised according to the experts\' suggestions to enhance its feasibility and readability of elements. The implementation of i-KAM would help software house in delivering software projects within prescribe cost and time. Monitoring software project development is essential to ensure that the project progress is according to budget, schedule, and quality expectations. Currently, Agile Methods (AMs) have received wide recognition within the software engineering (SE) field due to their flexibility and effectiveness. One of the AMs methods used in managing software project development is Kanban method. This method is gaining attention due to its ability to enhance understanding, visibility, and controlling the project workflow. Thus, this paper aims to discuss the initial result of the proposed model for improving the software project monitoring task of the Agile Kanban method (i-KAM). To achieve this aim, the expert review method was used to ensure that suitable components and associated criteria have been included in i-KAM. In this study, six domain experts, which are software practitioners, have been identified based on predefined characteristics. The proposed model was verified based on five dimensions, which are understandability, relevance, feasibility, organization, and comprehensiveness. The experts\' opinions and comments were obtained and subsequently quantified by using descriptive analysis. Findings revealed that this study has fulfilled its objective and has acquired constructive suggestions from the practitioners\' perspective. Future work will continue to enhance i-KAM according to the recommendations and remarks from the experts. A focus group and case study methods could be conducted in order to validate the revised i-KAM. Besides, a prototype will be developed and then implemented within a real software development setting.'),(11,'Omar, Mazni','https://www.scopus.com/authid/detail.uri?authorId=36608821700','Systems and its success evaluation are an important prospect whereby, several studies can be traced, outlining its importance and vitality. However, there is a need to identify responsive specific factors to help better understand the systems determinants and its success evaluation. In the academia, systems are used to facilitate students, human resource, e-commerce activities any much more. Hence, examining the systems and evaluating as to what length it is successful is essential. This study aims to provide the results of the hypothesis testing. There have been 7 accepted hypothesis and 3 rejected hypotheses. Hypothesis results showed that ISO 25010 works better than TAM and DM Models in systems success measurement. An extensive number of engineered frameworks and web assessment accessible are not good enough in the appraisal of systems\' quality. Thus, the comprehension of the systems\' quality in Mukalla, is basically critical. The research literature review aims at developing a successful novel theoretical approach for measuring system. The research contribution can be seen theoretically, in the methodology and practical perspectives. Theoretically, it presents a refined expansion of up-to-date DeLone and McLean\'s information success framework (2003), TAM and ISO 25010 posits that some factors are directly related to satisfaction. The need to answer why users dislike system after the initial experience must be known. Methodologically, the contribution of the research study will be performed using census and other data collection processes from student were instruments will be validated by 8 experts. Lastly, some factors like loyalty, security and benefits would be adapted and employed on non-commercial settings. Nowadays systems failure is the dominant of current research in the fields of information systems and software engineering. The rate of systems fails, and dissatisfying users are high with a lack of appropriate framework that can be used as a success measure in the context. With mix of the results in systems success measure. The organization is in need for a well-defined engineered framework to assist in the success measure of web-based systems. Yemeni south region\'s universities are facing the problem (dissatisfying users, justifying the cost of implementing systems and measuring its success). This study aims to propose the characteristics of a quality framework suitable for such a purpose and context of developing a novel systems quality framework based on adapting Delone & Maclean 2003, ISO 25010 and Tam to measure the success and quality of these web-based systems. Researchers validated the framework and instrument via 8 academic specialized lecturers in systems and software engineering from (Malaysia, Yemen and India). Researchers then confirmed the translated questionnaire (English to Arabic and back to back translation) with an authorized translation company. Before starting the pilot study, pre-test has been conducted with nine respondents to see if there is any doubts or unclear syntax, everything was OK. Pilot results showed an excellent result. Due to globalization and speedy of ICT and systems development, more emphasis needs to be on quality of systems and it requires an accurate, fast, effective system so that the success measure of system is essential. Currently systems rate of fall is still a high one of the reasons behind that is the weakness of the available instruments that being used for systems success measurement. This study aims to come out with a successful instrument for successfully system quality measuring. In this article, the results of the pilot test have been illustrated. This paper presents the verification results of the proposed model for improving the software project-monitoring task of the Agile Kanban method (i-KAM). However, i-KAM is still in its initial phases and requires verification regarding the proposed components and associated criteria. Expert review method was used to collect valid and reliable data from experienced persons who have skills and experiences in Agile software development. There were 11 experts participated and their opinions were obtained and quantified by using descriptive analysis. Results confirm that i-KAM is a well-accepted model as it can improve the progress monitoring task in terms of extending its tracking mechanism, controlling the WIP limits, and providing useful insights on the project status. Thereafter, i-KAM was revised according to the experts\' suggestions to enhance its feasibility and readability of elements. The implementation of i-KAM would help software house in delivering software projects within prescribe cost and time. Monitoring software project development is essential to ensure that the project progress is according to budget, schedule, and quality expectations. Currently, Agile Methods (AMs) have received wide recognition within the software engineering (SE) field due to their flexibility and effectiveness. One of the AMs methods used in managing software project development is Kanban method. This method is gaining attention due to its ability to enhance understanding, visibility, and controlling the project workflow. Thus, this paper aims to discuss the initial result of the proposed model for improving the software project monitoring task of the Agile Kanban method (i-KAM). To achieve this aim, the expert review method was used to ensure that suitable components and associated criteria have been included in i-KAM. In this study, six domain experts, which are software practitioners, have been identified based on predefined characteristics. The proposed model was verified based on five dimensions, which are understandability, relevance, feasibility, organization, and comprehensiveness. The experts\' opinions and comments were obtained and subsequently quantified by using descriptive analysis. Findings revealed that this study has fulfilled its objective and has acquired constructive suggestions from the practitioners\' perspective. Future work will continue to enhance i-KAM according to the recommendations and remarks from the experts. A focus group and case study methods could be conducted in order to validate the revised i-KAM. Besides, a prototype will be developed and then implemented within a real software development setting.'),(12,'Zolkipli, Mohamad Fadli','https://www.scopus.com/authid/detail.uri?authorId=36199074000','This study adopted a metaheuristic approach based on the firefly algorithm (FA) optimization to generate an appropriate configuration for an 8 أ— 8 Substitution boxes (S-boxes). The FA can construct a strong S-box that satisfies the stipulated criteria by rapidly searching for the optimal or near-optimal feature subsets that minimize a given fitness function. The FA is a newly developed computation technique inspired by fireflies and their flash lighting process. However, FA may suffer from premature convergence when solving optimization problems. This study proposes a new FA modification, namely, globalized firefly algorithm (GFA), which employs random movement based on the best firefly using chaotic maps. The best firefly does not conduct any search in the standard firefly algorithm (SFA). The proposed algorithm utilizes a new design for retrieving strong S-boxes based on SFA and GFA. Bijectivity, strict avalanche criteria, nonlinearity, input/output XOR distribution, bit independence criteria, and linear probability were also analyzed. The result was compared with a few previous S-box generation methods. Overall, the experimental outcome revealed that the design of the proposed S-boxes has satisfactory cryptographic characteristics. The COVID-19 disease has once again reiterated the impact of pandemics beyond a biomedical event with potential rapid, dramatic, sweeping disruptions to the management, and conduct of everyday life. Not only the rate and pattern of contagion that threaten our sense of healthy living but also the safety measures put in place for containing the spread of the virus may require social distancing. Three different measures to counteract this pandemic situation have emerged, namely: (i) vaccination, (ii) herd immunity development, and (iii) lockdown. As the first measure is not ready at this stage and the second measure is largely considered unreasonable on the account of the gigantic number of fatalities, a vast majority of countries have practiced the third option despite having a potentially immense adverse economic impact. To mitigate such an impact, this paper proposes a data-driven dynamic clustering framework for moderating the adverse economic impact of COVID-19 flare-up. Through an intelligent fusion of healthcare and simulated mobility data, we model lockdown as a clustering problem and design a dynamic clustering algorithm for localized lockdown by taking into account the pandemic, economic and mobility aspects. We then validate the proposed algorithms by conducting extensive simulations using the Malaysian context as a case study. The findings signify the promises of dynamic clustering for lockdown coverage reduction, reduced economic loss, and military unit deployment reduction, as well as assess potential impact of uncooperative civilians on the contamination rate. The outcome of this work is anticipated to pave a way for significantly reducing the severe economic impact of the COVID-19 spreading. Moreover, the idea can be exploited for potentially the next waves of corona virus-related diseases and other upcoming viral life-threatening calamities. Given a scale expansion of Internet of Things for sustainable resource management in smart cities, proper design of an intrusion detection system (IDS) is critical to safeguard the future network infrastructure from intruders. With the growth of connected things, the most-widely used centralized (cloud-based) IDS often suffers from high latency and network overhead, thereby resulting in unresponsiveness to attacks and slow detection of malicious users. In this paper, we address the limitation of centralized IDS for resource-constrained devices by proposing two methods, namely semi-distributed and distributed, that combine well-performing feature extraction and selection and exploit potential fog-edge coordinated analytics. In order to distribute the computational tasks, we individually develop parallel machine-learning models corresponding to a partitioned attack dataset. In the semi-distributed case, the parallel models, running on the edge side, are applied for side-by-side feature selections, which are then followed by a single multi-layer perceptron classification running on the fog side. In the distributed case, the parallel models individually perform both the feature selection and multi-layer perceptron classification after which the outputs are combined by a coordinating edge or fog for final decision making. Based on the comparative study of existing works, the numerical results demonstrate the promise of the proposed methods, giving a comparable detection accuracy to the superior centralized IDS as well as exemplify their inherent trade-offs between the accuracy and building time performance. Botnets have become one of the most significant threats to Internet-connected smartphones. A botnet is a combination of infected devices communicating through a command server under the control of botmaster for malicious purposes. Nowadays, the number and variety of botnets attacks have increased drastically, especially on the Android platform. Severe network disruptions through massive coordinated attacks result in large financial and ethical losses. The increase in the number of botnet attacks brings the challenges for detection of harmful software. This study proposes a smart framework for mobile botnet detection using static analysis. This technique combines permissions, activities, broadcast receivers, background services, API and uses the machine-learning algorithm to detect mobile botnets applications. The prototype was implemented and used to validate the performance, accuracy, and scalability of the proposed framework by evaluating 3000 android applications. The obtained results show the proposed framework obtained 98.20% accuracy with a low 0.1140 false-positive rate.'),(13,'Nadzir, Maslinda Mohd','https://www.scopus.com/authid/detail.uri?authorId=57193818884','The role of a website is becoming vital in supporting the daily function of a public university. Public university websites are now becoming more like a hub that offers various services for various categories of users. With the different type of users, it posed a new challenge for web designers, especially in term of integrating the web usability and aesthetics to ensure it is suitable for all users. Both usability and aesthetics have its own importance in the overall web performance thus requires a proper integration mechanism. In order to ensure that there is a guideline for web designers to assist them in designing a proper website, a model was developed that functions as a guideline in assisting web designers to design a public university website that not only high in term of usability but at the same time pleasing in term of aesthetics. The model has gone through a verification process through experts is web design field to ensure that the model was in line with the appropriate HCI principle and web design practice. After the process was done, the model needs to be validated to ensure that it is practical to be used during the actual web design process. In this paper, it discussed the validation process and the results of the validation of the model that was developed. The model was validated by public universities web designers to ensure that this model is practical to be used during designing a public university website. The role of a website is becoming vital in supporting the daily function of a public university. Public university websites are now becoming more like a hub that offers various services for various categories of users. With the different type of users, it posed a new challenge for web designers, especially in term of integrating the web usability and aesthetics to ensure it is suitable for all users. Both usability and aesthetics have its own importance in the overall web performance thus requires a proper integration mechanism. In order to ensure that there is a guideline for web designers to assist them in designing a proper website, a model was developed that functions as a guideline in assisting web designers to design a public university website that not only high in term of usability but at the same time pleasing in term of aesthetics. In this paper, it discussed the verification process and the results of the verification of the model that was developed. The model was verified through experts in the field of web usability, web aesthetics and web design to ensure the model comply to the requirements of HCI and web design practice. Social media platforms usage by government agencies is a major trend in electronic government (egovernment) practices, serving as one alternative for improving e-government services and enhancing information dissemination to the citizens. It is an issue for government agencies to connect with citizens through social media platforms. However, government agencies should support the usage of social media platforms to engage with more citizens. There are currently limited studies conducted on social media interactions in Malaysian government agencies\' social media platforms. Therefore, this study explores the features affecting citizens\' engagement in government agencies\' Facebook page, which is a social media platform. We conducted a survey in the Kedah state, Malaysia. A total of 475 questionnaires were administered to the citizens. The findings established that the trust in government is a prominent factor in inducing the citizens\' connection with the government agencies\' Facebook page. These results can provide new insights to government agencies based on the importance of developing social media strategies to interactively promote and engage social media platforms. The increase of user-generated content (UGC) on the Internet has led previous studies to propose various sentiment analysis approaches to understand public opinion. The primary goal is to enhance engagement through social media by analyzing various feedback. Sentiment analysis is performed based on two approaches i.e. machine learning and lexicon-based. Since approaches based on machine learning require costly preparation of training dataset and the approaches based on lexicon produce unsatisfactory performance, in this paper, both approaches are combined to perform sentiment analysis on Facebook comments. The importance of a lexicon-based approach to automatically construct the labeled data for machine learning sentiment classification is discussed in this paper. Experiments performed using the Universiti Utara Malaysia (UUM) Facebook posts show that using the combined lexicon-based and machine learning approach on two classifiers i.e. Naأ¯ve Bayes and Support Vector Machine outperform the single approaches to produce more accurate sentiment classifications.'),(14,'Pozi, Muhammad Syafiq Mohd','https://www.scopus.com/authid/detail.uri?authorId=57219746822','The new pandemic disease caused by COVID-19 virus is the crucial event over the world in the beginning of 2020. Studies on corona viruses have been however carried since several decades ago, with recent research papers published on weekly basis. We demonstrate a simple approach to explore CORD-19 dataset to provide a high level overview of important semantic changes that occurred over time. Our method aims to support better understanding of large domain-specific collections of scholarly publications that span long time periods and could be regarded as complementary to frequencybased analysis. Nowadays, real time feed video data are publicly available through various social network platforms. These data might be a live CCTV recording, news broadcast, parliament session, and so on. As the data usually contains many interesting events, various video semantic analysis tasks can be performed, such as video summarizing, motion detection, face recognition, video tracking and style detection, for the purpose of extracting these events from large video datasets. In this paper, we propose a face recognition module to be used for video content analysis of the Parliament of Malaysia sessions. The proposed system is expected to help Malaysian citizens in identifying their respective parliament representative\'s performance in quantitative and more objective manner. In order to perform comprehensive analytic task, it requires the availability of any particular complete dataset in the first place. However, due to privacy concern, the specific demand on sharing full dataset to third parties is hardly to be fulfilled. New methods using systematically synthetic data generation in order to preserve the data privacy have recently been explored and identified as a suitable ap-proach to address the privacy concern. Throughout this work, a privacy-preserving probability based synthetic data generation framework for supervised based data analytic is proposed. Using a generative model that captures and represents the probability density function of dataset features, a new privacy-preserving synthetic dataset is synthesized, such that, the new dataset is statistically different from the original dataset. Then, we simulate a supervised learning task using two different machine learning classifiers, as a method to compare the utility of original and the new privacy-preserving synthesized dataset. From the experimental results, we found that the proposed synthetic generation model can produces a new privacy-preserving synthesized dataset, that has similar data utility as to the original dataset. Digital footprints can be defined any data related to any online activity. When engaging, the user leaves digital footprints that can be tracked across a range of digital activities, such as web explorer, checked-in location, YouTube, photo-tag and record purchase. Indeed, the use of all social media applications is also part of the digital footprint. This research was, therefore conducted to classify the types of digital footprint data used to predict psychographic and human behaviour. A systematic analysis of 48 studies was undertaken to examine which form of digital footprint was taken into account in ongoing research. The results show that there are different types of data from digital footprints, such as structured data, unstructured data, geographic data, time-series data, event data, network data, and linked data. In conclusion, the use of digital footprint data is a practically new way of completing research into predicting psychographic and human behaviour. The use of digital footprint data also provides a tremendous opportunity for enriching insights into human behaviour.'),(15,'Nor Hazlyna, H.','https://www.scopus.com/authid/detail.uri?authorId=36166820300','leukaemia is a disease which develops in the bone marrow, causing a large formation of abnormal cells and usually affected adults. The process of inspecting visually on the microscopic images is time consuming and a tiring process. The developed technique is aimed at assisting the haematologists upon identifying the presence of nucleus in blood cell images. Therefore, this technique is hoped to aid the haematologists in early and fast identification of leukaemia. This paper will be focusing on Acute Myeloid Leukaemia (AML). This research work proposed a combination of methods for the detection of Leukaemia using image processing techniques such as Lâˆ—Aâˆ—B colour-based thresholding algorithm, Sobel edge detection algorithm, and watershed distance transform to identify the nucleus blasts of leukaemia cells from blood cells image. The developed technique shows that it is able to produce the image of segmented nucleus blasts. Leukemia is a type of cancer that affects the white blood cell. Early detection of leukemia is important to reduce the rate of mortality. In order to detect acute leukemia, conventional screening method based on microscopic image is used, where sample of blood cell will be taken from the suspected leukemia patient and manually white blood cell (WBC) condition is observed using microscope. The manual screening process is tedious, time consuming and usually prone to error due to low contrast between the nucleus and cytoplasm of WBCs. This report introduces a new enhancement method which is a combination of Particle swarm optimization (PSO) algorithm and contrast stretching, known as Hybrid PSO-Contrast stretching (HPSO-CS). The PSO has been used to optimize the fitness criterion in order to improve the contrast and detail in microscopic image by adapting the parameters as a contribution to enhancement technique. In this study, PSO algorithm is used to perform image segmentation to remove all the unwanted part such as red blood cell (RBC), platelet and also the background while retain the WBC part. The segmentation algorithm uses saturation S-component based on Hue, Saturation, Intensity (HSI) color model. After the segmentation is done, contrast stretching process is applied to the original image to stretch intensity of the pixel. Then the segmented image is combined with the resultant image that has been stretched to produce the enhanced image. The results of the proposed method are evaluated by using mean-square error (MSE), Peak-signal-to-noise-ratio (PSNR) and Absolute mean brightness error (AMBE). This proposed method is benchmarked by comparing against two image enhancement methods, global enhancement and Class Limited Adaptive Histogram Equalization (CLAHE). Based on the results, it can be concluded that quality of the enhanced image for the proposed method is much better with the lowest MSE (2067.651), AMBE (43.51827) and highest PSNR (14.98671) compared to the global and CLAHE method. The proposed method can improve the screening process and assist haematologist in leukemia screening and detection by improving the visual appearance of the WBC. In Malaysia, Non-mydriatic fundus camera become a primary tool for Diabetic Retinopathy screening protocols due to user friendly and cost effective procedure. However, the quality of fundus image produces often suffer from uneven illumination, color distortion, blur, and low contrast. Therefore, the need for image enhancement become crucial to be implemented as a pre-processing technique in image processing funnel. This paper presents six general basic methods that commonly applied for image enhancement which includes histogram equalization, contrast stretching, image negative, brightness enhances, low light image and gray level slicing. The performance evaluation of each method compared based on human interpretations and quantitative measurement using MSE, PSNR and entropy. Retinal fundus images collected from Ophthalmology Clinic, Hospital Universiti Sains Malaysia were used as the input images. Quantitative and qualitative result shows that CS method become the preferred method to be used for image enhancement of retinal fundus image in Diabetic Retinopathy.'),(16,'Ibrahim, Huda Bt Hj','https://www.scopus.com/authid/detail.uri?authorId=23397046500','The evolution of Blockchain introduces the first cryptocurrency and continues to attract public attention. Being an open-source project, disagreements among development communities often lead to the loss of committers. The projects always in-search for a new committer to spur innovation but come with hard fork risk. Prior promotion models are based on the developer\'s technical activities. However, there is a lack of academic research that investigates developer commitment. Drawing literature from open-source projects, such as Mozilla, Apache and Social Cognitive Theory, this paper proposes a model that integrate SCT constructs and Blockchain decentralization to examine the factors that influence developer commitment in cryptocurrency project. This study proposes a quantitative approach by collecting data from online survey to evaluate the proposed model using partial least square structural equation modelling (PLS-SEM). This paper is expected to be a valuable contribution to project leaders and community to identify committed developer and antecedent factors. Given the possibilities of smart cities to significantly affect human lives, issues related to security have come into a spotlight to public and industries. People are now connected to each other through smart telephones and other gadgets. Facilities like smart meters, security gadgets and smart machines are being utilized in numerous cities. This study presents the security measures in the context of smart city advancement. Security matters in this context encompasses unlawful access to information and attacks causing physical disturbances in administration accessibility. Semi-structured interviews on 30 government officials, policymakers and regulators were applied to saturate categories. The outcome uncovered a dimension of \'evolving security\' as having positive effect and prompts how King Hussein Business Park (KHBP) is a mix for planning a robust security initiative for the securing of a smart city. City foundations and administrations are now evolving and experiencing changes amidst new interrelated systems for monitoring, control, and automation. Smart transportation, open and private, will get to a snare of interrelated information from GPS area to weather and traffic updates. Integrated systems will help open wellbeing, emergency responders and in misfortune recuperation. The development of information and communication technology has spread throughout the world. Many benefits can be obtained, but the risks cannot be avoided. Communication grows massively in cyberspace and thus poses a security threat to smart city services. This threat can be overcome through national spectrum by implementing cyberspace security strategies in developing smart cities. This paper describes cybersecurity strategies performed in supporting the development of smart cities. Security strategies are developed based on factors related to the perspective of three pillars of smart city implementation models, namely technology, people, and institutions. Factors related to cybersecurity from these three pillars are explored from the experience of policy makers, actors, and users of smart city services, and evaluated using the opinions of cybersecurity experts and smart cities. This strategy will be a standard document that will be used as a reference in carrying out all processes related to information security in supporting the development of smart cities. In this paper, we highlighted the importance of User Experience (UX) sketching as one of the skillsets required for UX researchers in project development especially in low participatory design awareness countries like Malaysia. This is due to the results from UX research activities that are not perceived to be impactful by developers, designers and other stakeholders in digital transformation projects especially by the government that has been suffering from vendor-centric Request for Proposal (RFP) tender for the past 60 years. In consequences, time taken by developers to code from requirements captured by business analysts is longer than visual representation produced by UX or UI designers, which shortens the requirement gathering process. In conclusion, we found that UX sketching that produces visual representation of user needs to be effective especially in participatory design approach and to reduce user frustrations. Global ever-increasing population and fast urbanization have created many problems. Many studies have identified smart city development as a vibrant solution to the problem. Review of the existing studies signified that smart citiesâ€™ development have many models and dimensions. However, this study explored and identified technology-based smart city development model, given the fact that technology is regarded as an enabler that can connect physical distances in a many way, which consequently creates opportunities for quickened social and economic practices for people. This study used grounded theory because there no stander for smart city development framework. This study applies semi-structured interviews with 30 government officials, policy makers and regulators in several trips to the field to saturate categories. The result revealed the category â€œestablishing technologyâ€‌ describing how Jordanâ€™s Amman, King Hussein Business Park(KHBP) is a blend of technology-based dimensions: technology infrastructure, smart facilities, international IT companies, and applications. Based on this result, technology could be considered a crucial process to achieve smart city development, and the discovery of new technology promotes technology infrastructure, smart facilities, and applications which could be facilitated by international IT companies. Overall, this study generates a model that could be tagged â€œa technology-based smart city development dimensionsâ€‌ which could be examined and adopted by future study.'),(17,'Hussain, Azham','https://www.scopus.com/authid/detail.uri?authorId=56212649500','Having a considered that online storage and sharing has becoming an essential to organised, stay focused and get in sync contents for all team members to enlighten way to work. Dropbox is the world\'s first smart work space which bring content of all team members together whilst letting users use the tool they want. Dropbox was initiated in 2008. Based on the usefulness and benefits of Dropbox, there are many kinds of research has been conducted on this topic. Therefore, this paper aims to analyse the scientific literature and report various types of published documents related to the Dropbox based on the data obtained from the Scopus Database by using Perish software to combine the obtained data, VOS Viewer Software to visualize the obtained data and Microsoft Excel to analysis the obtained data analysis. As of 27thApril 2020, there are 506 documents were retrieved and analysed based on the â€‍key words\' search result thru database. By using standard bibliometric indicators, this paper reports the documents types, source types, publication years, language of publications, subject area, most active source title, keywords, distribution of publications by countries, authorship, text analysis, most active institutions and citation analysis. As the result show that 1) 81% of the articles were published in conferences proceedings and journals articles. 2) 91% of the articles were published in English. 3) There is an increased growth rate of literature on Dropbox since 1985. However, the growth rate is slightly lower from 2016 until 2018. 4) Computer Science is the most popular subject category with respect to the frequency of citations, Halevi, Harnik, Pinkas and Shulman-Peleg (2011)\'s article appears as the most cited paper with an average of 30.44 citations per year. 5) Keywords of the Digital Storage, Cloud Storages and Cloud Computing were the top three keywords used in the database which represented the main areas of about Dropbox. 6) An analysis by country, The United States (US) is first country published most articles about Dropbox with 138 (27.27%).Meanwhile, 6) a total of 446 (88.14%) articles were published as multi-authored with a mean index of 3.55 authors per paper. Therefore, this research reviews of Dropbox published articles and delivers details of growth of Drop box for these35 years. This may help in potential directions or reference for future research. آ© 2021. All rights reserved. Ever since cloud storage has been a trend for data storage technology, Google Drive has been widely used by users and research on the use of Google Drive has initiated starting from 2012. Based on the usefulness and benefits of Google Drive, there are many kinds of research has been conducted on this topic. Thus, this paper aims to analyze and report various types of published works related to Google Drive based on the data obtained from SCOPUS database as of May 2020. This study adopted a bibliometric analysis by using â€œGoogle Driveâ€‌ keyword search and managed to retrieve 356 documents to-be analyzed. Standard bibliometric indicators has been used to present the result in this article; document type, source type, year of publication, languages of document, subject area, most active sources, keyword analysis, geographical distribution of documents, authorship and most productive authors, most influential institution, text and citation analysis. MS Excel, VOS viewer, and Publish and Perish 7 software had been utilize in order to analyze the gathered documents. The result shows there is an increased growth rate of research on Google Drive from 2012 until 2016. However, the number of research is decreasing slowly from 2017 until 2020. In total, there are 9 languages being used, 26 subjects area with one undefined, 73 countries with one undefined, 160 authors and 160 institutions. آ© 2021. All rights reserved. There are several literatures pertaining to the self-efficacy of student, and educational mobile apps, but no work has been done yet on the improving the academic self-efficacy of students using mobile educational apps. This study therefore employed systematic review methodology to ascertain the factors necessary to be considered while using educational mobile apps in order to improve the academic self-efficacy of students. Hence, this paper attempts to review available literatures with the aim of capturing means of improving the academic self-efficacy of students using mobile educational apps. To achieve the stated research objective, the study applied systematic literature review methodology. Fifty (50) papers relating to academic self-efficacy of students using mobile educational apps were downloaded. Out of these papers, nineteen (19)most relevant studies were selected for review in order to extract the appropriate information needed for the analysis. The results from the review revealed that the major causes of studentsâ€™ low academic self-efficacy are: lack of confidence with 22.73% and others include: low self-esteem (21.05%) and inferiority complex (10.53%). Also, the review was able to show the three most important factors necessary for improving the academic self-efficacy of students using mobile educational apps included: teachersâ€™ message (21.05%) and success and failure of others (15.79%). آ© 2021. All Rights Reserved. Although, there are several literatures pertaining to the security issues in the use of mobile apps, these literatures do not sufficiently address issues about the security challenges in the use of mobile educational app. Hence, this work attempts to review the available literatures with the aim of capturing the security issues in the use of mobile educational apps. To achieve the stated research goal, the study applied systematic literature review methodology. Sixty-four (64) papers in the area of security issues in the use of mobile educational apps were downloaded. Out of these papers, twenty-one (21) most relevant studies were selected for review in order to extract the appropriate information needed for the analysis. The results from the review reveals the scarcity of appropriate literatures on security issues in the use of mobile educational apps and that these issues are a thing of concern, and needed to be looked into in this ever-growing world of technologies. However, most of the studies, taken single handedly reviewed lack of comprehensive framework to demonstrate the security challenges in the use of mobile educational apps. Thus, the results from this paper provide additional knowledge to the users of mobile apps as a whole; students in their usage of mobile educational apps and the research community on the current security challenges in the use of mobile educational apps. آ© 2021. All Rights Reserved.'),(18,'Haji Ahmad, Azizah','https://www.scopus.com/authid/detail.uri?authorId=56763298400','The purpose of this study is to investigate the quality design criteria for developing a Massive Open Online Course (MOOC). Currently, there are limited studies that highlight the required design criteria for the MOOC programming courses. A descriptive analysis was conducted to examine the characteristics of the three important quality design criteria which are (i) Instructional Design Criteria involving Lecture Organization and Culture; (ii) Technical Criteria involving User Interface, Video Content, Learning and Social Tools, and Learning Analytics; and (iii) E-Assessment. The data were collected from 306 respondents, representing the UUM MOOC students of 2018 class, were further analyzed using the T-Test hypothesis testing to determine whether both the programming and nonprogramming students require the same quality design criteria. The questionnaire used in this study consists of 46 items related to the MOOC quality design criteria that were adapted from previous studies. The results indicate that out of the nine constructs, four have obtained significant differences in the mean scores, namely the Video Content, Instructional Design, Culture, and E-assessment. This signifies that different quality design criteria are needed for both the programming and nonprogramming students. The outcome of this study may assist the developers in designing the MOOC by providing the required criteria according to its importance. This paper discusses a construction clearing house framework to bridge knowledge management gap in the Malaysian construction industry. A clearing house is an agreed upon mechanism for transferring knowledge, which includes a centralized repository of information and resources on a collection of specific topics that are accessible by interested stakeholders. The focus is on resolving the problem of managing domain knowledge of the construction industry in Malaysia, emphasizing on the knowledge management practices through the capturing and transferring of construction knowledge and best practices of the industry players. The knowledge management research framework used is improvised from the previous researchers, while the transfer and sharing of construction best practices is based on the adapted framework also proposed by the previous researchers. This paper briefly described five areas namely knowledge need analysis, knowledge inventory analysis, knowledge flow, knowledge mapping and the knowledge creation in clearing house framework for sharing/transfer of best practices. The construction knowledge and best practices clearing house framework would facilitate the development of a clearing house system in the future, which will enable players in the industry to both contribute and benefit from the resources contained in the clearing house system. This clearing house framework will enable knowledge management of governance inculcate a good environment for practicing conducive knowledge management through knowledge and best practices sharing in the Malaysian construction industry. Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur\'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur\'an corpus. Public health, safety and welfare of community is one of the important sustainable development goals. Basic water supply, electricity and waste disposal must be in optimum condition in promoting quality of life. Citizens need to be afforded with simple and usable system for reporting problems related to the public facilities and services to their local councils. Currently, there is no integrated online mechanism for reporting and monitoring the problems. This study proposes a simple and usable mobile application for reporting known as My Response. Additionally, how usability factors are related to intention of using this apps were analyzed. 40 local people participated in the usability study. Usability attributes accommodated in this application such as the instant start or launch feature, well and comprehensible designed icon positively correlates with intention to use the application. The usage of understandable terminology, concise language and minimal user effort required in MyResponse also positively correlates with intention to use. In our study, simplicity and understandability in using and navigating the apps is the golden rule.'),(19,'Yasin, Azman','https://www.scopus.com/authid/detail.uri?authorId=36448052100','Social media plays an important role in marketing specifically in digital marketing. Many entrepreneur and businesses start to promote their brand and items on the social media platform such as Instagram. The main objective of this study is to crawl data from Instagram and perform some simple analysis to get some entrepreneurial ideas. A system named Graduate Entrepreneur Opportunity Recognition System (GEORsys) is proposed in this study. Hashtags for custom words or sectors like agriculture, services, food and beverages (F&B), fashion, information, communication and technology (ICT) and logistics are used to crawl data from Instagram. Then, some simple visualizations are shown to conclude what keywords or hashtags are popular in Instagram. One of the data mining important tasks is clustering, and data stream clustering is a complicated process due to the infinite data arrival. Besides, the rapid growth of ICT, such as the deployment of the Internet of Things (IoT) in various real-world applications, has contributed to the overwhelming data stream. As data stream evolves over time, grouping the data into relevant clusters requires much of an attention. This paper discusses the various clustering algorithms used for the data stream and highlights their strength and weakness. To follow, proposed a new weighted function to cluster the evolving data stream. The main aim is to come up with a new cluster weight function that can enhance the evolving data stream clustering. The new function includes all the essential factors that affect data stream weight; some of these factors been missed by other studies. Pioneering opportunity acknowledgment assumes a significant job in perceiving and form an open door into an endeavor characterizes a business visionary. Research additionally shows that accomplished business visionaries quest and sweep for data to find openings. In light of other research, there is less spotlight on inquire about on finding experimentally demonstrated systems and strategies to create and upgrade opportunity acknowledgment in understudy business visionaries. This study aims to explore factors that improving entrepreneurial opportunity recognition. The study found three factors are family background, individual desire, and education which measures the elements that improving entrepreneurial opportunity recognition. The factor will be evaluated through quantitative methods enable student entrepreneurs to generate more business ideas that are more innovative and viable. This component article introduces the discoveries of the investigation, and examines potential consequences and remedies.'),(20,'Baharom, Fauziah','https://www.scopus.com/authid/detail.uri?authorId=43061015400','One of the principles in Agile is to promote sustainable development and requirements are the key point to develop sustainable software systems. One way to achieve sustainability as a software development is to make it to be the part of the product quality as a Non-Functional Requirements (NFRs). Agile Software Development (ASD) often focuses Functional Requirements (FRs) due to the nature of Agile and ignores Non-Functional Requirements (NFRs) during the process of requirement change. However, ignoring NFRs has negative impacts on software products and lack of careful consideration, increases the risk of project failure. The main objective of this article is to identify the sustainability characteristics and sub-characteristics that can be helpful to further explore the interlinked relationship of sustainable quality characteristics with managing changes in ASD to achieve software sustainability. The preliminary analysis identified sustainability characteristics such as maintainability, portability, usability, efficiency, interoperability, and reliability with their respective sub-characteristics. The identification of the sustainability characteristics sub-characteristics will serve as a first step during the process of Requirement change in ASD. Nowadays, most organizations have adopted IT outsourcing (ITO) into their main business strategy as it promises several benefits such as cost reduction, staff ability improvement and technology enhancement. Supplier selection is a key essential process in ITO. Unfortunately, supplier selection is a complex decision-making process as the evaluation involved with multi criteria and each criterion carries a different weight. Usually, the weight for each criterion is assigned by experts which might introduce uncertainty, bias, and opaqueness. Therefore, this paper proposed a hybrid method that aimed to eliminate human roles in determining evaluation criteria weight during supplier selection process. The method was designed by integrating Firefly Algorithm (FA) into Analytic Hierarchy Process (AHP) and termed as Firefly Algorithm Analytic Hierarchy Process (FAHP). It is operationalized on three datasets which were obtained from the referenced literature. Experimental results showed that the obtained Consistency Ratio (CR) value (i.e. 0.001) and Sum of Bias (SB) value (i.e. 0.351) are very close to zero. These findings show that the proposed FAHP is feasible to identify relevant supplier even though the criteria weight was determined without human involvement. Such an approach reduces human bias throughout AHP synthesis process. Consequently, the obtained weights were the optimal solution that can be adopted in the supplier selection problem. Software testing is anessential process for ensuring thequality and reliability of software products. The efficiency of testing activities depends largely on the test case quality, which is considered as one of the major concerns of software testing. Unfortunately, at the moment there is no clear guideline that can be referred by software testers in producing good quality test cases. Hence, producing guideline is certainly required. To construct a pragmatic guideline, it is crucial to identify the factors that lead todesigninggood quality test cases. The existing test case quality factors are not comprehensive and need further investigation and improvement. Therefore, a content analysis was conducted to identify the test case qualityfactors from software testing experts point of view available in the software testing websites. The software testing websites provide explicit information about the quality of test cases in order to avoid the poor design of test cases. Thus, this study presents the outcomes of content analysis from 22 software testing websites which comprise of static content websites and blogs. Consequently, eight (8)factors and their corresponding 30 sub-factors were identified. Among the factors are documentation, manageability, maintainability, reusability, requirement quality, efficiency, tester knowledge, and effectiveness of test cases. These factors are useful to be referred by the practitioners in assuring the quality of the design test cases which implicitly can ensure the quality of the software products.'),(21,'Mohd, Haslina','https://www.scopus.com/authid/detail.uri?authorId=49964035900','Software testing is anessential process for ensuring thequality and reliability of software products. The efficiency of testing activities depends largely on the test case quality, which is considered as one of the major concerns of software testing. Unfortunately, at the moment there is no clear guideline that can be referred by software testers in producing good quality test cases. Hence, producing guideline is certainly required. To construct a pragmatic guideline, it is crucial to identify the factors that lead todesigninggood quality test cases. The existing test case quality factors are not comprehensive and need further investigation and improvement. Therefore, a content analysis was conducted to identify the test case qualityfactors from software testing experts point of view available in the software testing websites. The software testing websites provide explicit information about the quality of test cases in order to avoid the poor design of test cases. Thus, this study presents the outcomes of content analysis from 22 software testing websites which comprise of static content websites and blogs. Consequently, eight (8)factors and their corresponding 30 sub-factors were identified. Among the factors are documentation, manageability, maintainability, reusability, requirement quality, efficiency, tester knowledge, and effectiveness of test cases. These factors are useful to be referred by the practitioners in assuring the quality o f the design test cases which implicitly can ensure the quality of the software products. Service-Oriented Architecture (SOA) is an approach that can be used to integrate different services across operating systems, platforms, languages, and networks which offer some benefits. However, many organizations fail to fully utilize SOA because the adoption processes are still immature. Therefore, an exploratory study was conducted to investigate current issues and practices of SOA adoption, the use of maturity levels for assessing SOA adoption, and the importance of information technology (IT) and business benefits in SOA adoption. Thus, the Grounded Theory approach was adapted in this study which involved seven software development companies in Malaysia. In this study, 14 SOA practitioners with at least three years of experience in SOA development were interviewed. The collected data was analyzed through three main coding stages: open, axial and selective coding. The theory which emerged from this study revealed SOA adoption issues, current practices, maturity levels, IT and business benefits. The study managed to identify five main issues in SOA adoption which were knowledge, infrastructure, costing, readiness, and documentation issues. The study also portrayed five best practices related to technology, framework, platform, standards, and tools. In addition, results from the study showed five IT and business benefits, consecutively. The findings from the study have led to theories formulation on SOA adoption which may assist researchers and SOA assessors to continuously improve the quality and maturity of SOA adoption in the future. This paper explains the verification process of a proposed model for evaluating the usability of chronic disease management (CDM) applications. This research aims to symbolize main practices in evaluating the usability of the CDM application. Twelve (12) usability experts from academia, medical and mobile application development from around the globe participated in examining the model components. The experts completed a verification form and questionnaire that measured the model in terms of consistency, understandable, ease of use, tailorable, verifiable and overall impression. Furthermore, the proposed model has been modified based on the comments and suggestions received from experts. Similarly, the expertsâ€™ questionnaire result indicates that the proposed model is original, complete and acceptable. Therefore, this study will provide additional knowledge in both theory and practice towards model verification process, especially for usability evaluation of disease management applications. The ease of use while interacting with chronic disease management (CDM) applications leads the mobile application designers to integrate usability in their design process so that the usage of such applications become versatile, unique, user-friendly and successful. This paper aims to develop a usability evaluation model for CDM mobile applications through requirement gathering from real users and a systematic literature review (SLR). The analysis of current models and previous study results in a set of selected usability guidelines for mobile applications that are expended further into measurement model consisting of metric for evaluation.'),(22,'Husni, Husniza','https://www.scopus.com/authid/detail.uri?authorId=16039341100','In reality, students learn via eLearning (electronic online learning) system in different ways depending on their learning needs, learning behaviours as well as eLearning system policy for users. However, most learning outcome prediction models of eLearning systems are still not stable and still cannot be applied in many situations as the use of eLearning is considered to be highly dynamic. Therefore, the objective of this work is understand if eLearning system can be predicted based eLearning usage by exploiting Moodle log data. To understand it, features from web log course-student in Moodle is being considered, a number of machine learning techniques also have been applied for benchmarking in this study. The result found that the current group doesn\'t give better understanding and significant groups of factors that could be able to predict the learning outcome. The performance of Multinomial Logistic Regression (MLR) is highly dependent on the estimated value of its parameters (Regression Coefficients - RCs). However, the usual maximum likelihood estimation (MLE) approach of RCs mostly resulted in overfitting the regression model, especially in limited data. Hence alternatives approach (shrinkage) such as Lasso and ridge were proposed. The shrinkage process at times might eliminate important predictors by shrinking the RCs values to zero. We proposed data splitting and swapping approach aimed at eliminating the identified problems in the existing estimation approaches while improving the performance of MLR. Two algorithms were implemented for determining the best set of RCs (DBRCs) which are DBRCs-I and DBRCs-II. Experimental results show that one of the approach- DBRCs-II outperforms the conventional MLE, approach by 2.05 % in overall recognition of Malay vowels. Given enough data for training, DBRCs-I swapping techniques can be use as good technique to obtain good RCs faster. Sentiment analysis has become one of the most common method to classify stock market behaviour. Moreover, sentiment analysis has gained a lot of importance in the last decade especially due to the availability of data from social media such as Twitter. However, the accuracy of stock market classification models is still low, and this has negatively affected the stock market indicators. In this research, a model for GCC stock market classification based on sentiment analysis is constructed. It is designed to enhance the classification accuracy by the incorporation of tweet timestamp and location features, stock market domain expert labelling technique and the construction of a hybrid Naأ¯ve Bayes classifiers to classify the stock market sentiments. The methodology for this research consists of six phases. Data collection, labelling technique, data pre-processing, classification, performance and evaluation, and the final phase is recognition for the stock market behaviour. The model produced a significant result in classifying stock market behaviour with accuracy more than 89%. The model is beneficial for investors and researchers. For investors, it enables them to formulate their plans based on accurate indicators whereby it reduces the risk in decision making. For researchers, it draws their attention to the importance of feature engineering, labelling technique, and the classifiers hybridization in enhancing the classification accuracy. The usage of emoticon in computer-mediated communication has been growing rapidly among users, especially in social media. Emoticon has been used to express feelings, emotions, gestures, actions and places. Despite the growing number of emoticon users around the world, study on the cultural elements of the emoticon is still lacking. This research aims to propose a model for the development of Culturicon, which is Cultural-Based Emoticon. In doing so, a verification process must be done to the proposed model to ensure that the model is well verified. Expert review method was used for the verification method. Experts from the field of Human-Computer Interaction, User Experience and cultural study especially the academicians were chosen. In addition, application developer and graphic designer also were chosen as expert from the industry. The experts were approached by email and performed the verification by answering online questionnaire provided. The result obtained from these experts were analyzed and amendment were made based from the comments and suggestions. Results showed that 91% experts agreed the connections and flows of all components in the proposed model are logical and readable. Expert verification is important to ensure that the model is being develop correctly. By having this model, it can aid designer and developer in designing meaningful and effective culturicon.'),(23,'Ahmad, Mazida','https://www.scopus.com/authid/detail.uri?authorId=55456467900','Designing a Central Repository (CR) for supporting the domain of Interlocking Institutional Worlds (IWs) requires a theory or model from Knowledge Storage Process (KSP) literature to govern the stakeholders\' participation in the CR platform. However, current KSP theories or models have limited capabilities, so there are clear gaps in the context of designing a CR for the domain of IWs. Therefore, this paper suggests processes which include Identification, Standard, Service, and Maintain (ISSM) as a new KSP model to fill these gaps. To understand the stakeholders\' participation, the authors use the case study of Flood Management (FM) to make sense of the proposed ISSM model. This gives us better understanding towards CR design using the KSP model. Knowledge management (KM) is gaining significance as a worthy research subject due to its contribution to the success of wide range of organizations, including higher education institutions. Knowledge internalization is mainly related to capability to see the relevance of one\'s knowledge in a real situation. e-learning management system (eLMS) provides an online teaching and learning platform for students (as novice users) and lecturers (as experts in their specific domains) with the potential to improve students\' knowledge acquisition. Thus, this empirical study was conducted to investigate the impact of knowledge internalization in eLMS among students in Iraq. To achieve these aims, survey research design was adopted and the sample comprised of 109 undergraduate students attending College of Information Technology in Iraq, all of whom were actively engaged in eLMS activities. The findings show that knowledge can be effectively transferred from lecturers to students via eLMS. Additionally, eLMS enable students to improve their prior knowledge through the internalization process, while also motivating them to share their knowledge with other students. Interlocking Institutional Worlds (IWs) is a concept explaining the need to interoperate between institutions (or players), to solve problems of common interest in a given domain. Managing knowledge in the IWs domain is complex, but promoting knowledge sharing based on standards and common terms agreeable to all players is essential and is something that must be established. In this sense, ontologies, as a conceptual tool and a key component of knowledge-based systems, have been used by organizations for effective knowledge management of the domain of discourse. There are many methodologies that have been proposed by several researchers during the last decade. However, designing a domain ontology for IWs needs a well-defined ontology development methodology. Therefore, in this article, a survey has been conducted to compare ontology development methodologies between 2015 and 2020. The purpose of this survey is to identify limitations and benefits of previously developed ontology development methodologies. The criteria for the comparison of methodologies has been derived from evolving trends in literature. Our findings give some guidelines that help to define a suitable methodology for designing any domain ontology under the domain of interlocking institutional worlds. The development of Virtual Reality in the Training and Education domain (VRT for short) involves a huge amount of knowledge related to interactive graphics, and also requires bridging the knowledge among stakeholders. However, studies on how the knowledge is captured explicitly are still lacking. Thus, the main purpose of this study is to explore how ontologies have recently been applied in the VRT domain. A narrative method was conducted with the support of Kitcheman\'s Systematic Literature Review (SLR) methodology. In summary, the key findings of this work are: (i) Majority of the studies only focus on capturing & structuring knowledge; (ii) All ontologies apply deficient foundational ontologies, languages and methodologies when designing ontologies for VRT; (iii) Lack of capturing perdurant knowledge in ontology design (iv) There are key components that are considered crucial for designing an ontology for VRT. Future directions are suggested for designing the right ontology for VRT. The development of Virtual Reality in the Training and Education domain (VRT for short) involves a huge amount of knowledge related to interactive graphics, and also requires bridging the knowledge among stakeholders. However, studies on how the knowledge is captured explicitly are still lacking. Thus, the main purpose of this study is to explore how ontologies have recently been applied in the VRT domain. A narrative method was conducted with the support of Kitcheman\'s Systematic Literature Review (SLR) methodology. In summary, the key findings of this work are: (i) Majority of the studies only focus on capturing & structuring knowledge; (ii) All ontologies apply deficient foundational ontologies, languages and methodologies when designing ontologies for VRT; (iii) Lack of capturing perdurant knowledge in ontology design (iv) There are key components that are considered crucial for designing an ontology for VRT. Future directions are suggested for designing the right ontology for VRT.'),(24,'Omar, Mohd Hasbullah','https://www.scopus.com/authid/detail.uri?authorId=55994191800','The design of next Vehicular Ad-hoc Network (VANET) in various technologies will offer seamless connectivity across different coverage. However, VANETâ€™s vertical handover (VHO) decision in seamless connectivity is a huge challenge caused by the network topology complexity. Furthermore, the conventional scheme only uses a received signal strength as a metric value, which shows a lack of appropriate handover metrics that is more suitable in horizontal handover compared to VHO. This study aims to design an intelligent network to minimize the handover delay and latency, and packet loss in the heterogeneous Vehicle-to-Infrastructure (V2I) wireless networks. The proposed intelligent-based scheme uses Fuzzy Logic (FL) that generates multiple attributes parameters using the information context of vertical handover decision in the V2I heterogeneous wireless networks. This study uses a network simulator as the mobility traffic network and vehicular mobility traffic generator to perform a topology in a realistic VANET mobility scenario via Wi-Fi, WiMAX, and LTE networks technologies. The proposed intelligent scheme shows an improvement in the QoS handover over the conventional (RSS-based) scheme with an average QoS increased of 21%, 20%, and 13% in delay, latency and packet loss, while Media Independent Handover based (MIH-based) scheme with 12.2%, 11%, and 7% respectively. The proposed scheme assists the mobile user enhanced the QoS handover during the vehiclesâ€™ movement without degrading the performance of ongoing applications. In order to perform comprehensive analytic task, it requires the availability of any particular complete dataset in the first place. However, due to privacy concern, the specific demand on sharing full dataset to third parties is hardly to be fulfilled. New methods using systematically synthetic data generation in order to preserve the data privacy have recently been explored and identified as a suitable ap-proach to address the privacy concern. Throughout this work, a privacy-preserving probability based synthetic data generation framework for supervised based data analytic is proposed. Using a generative model that captures and represents the probability density function of dataset features, a new privacy-preserving synthetic dataset is synthesized, such that, the new dataset is statistically different from the original dataset. Then, we simulate a supervised learning task using two different machine learning classifiers, as a method to compare the utility of original and the new privacy-preserving synthesized dataset. From the experimental results, we found that the proposed synthetic generation model can produces a new privacy-preserving synthesized dataset, that has similar data utility as to the original dataset. In heterogeneous wireless networks (HWNs), various wireless networks have signal ranges that overlap and cover each other. Enabling mobile users to access the most suitable network is one of the research topics on HWNs. This paper designs a multiattribute access selection algorithm supporting service characteristics and user preferences in HWNs, which includes five calculation modules: network attribute utility value, network attribute weight, network attribute score, user preference value, and candidate network comprehensive score. In addition, the algorithm proposed in this paper integrates the utility theory, fuzzy analysis hierarchy process (FAHP), fuzzy logic, and multiattribute decision-making (MADM) methods for a complete access selection scheme that considers different network performances, service characteristics, and user preferences. The simulation results show that the algorithm proposed in this paper can allow users to select the most suitable network while obtaining higher gains and reducing user handover between different networks. The ever increasing need for grid systems in scientific, business and â€œwhat ifâ€‌ real world types of applications, coupled with the dynamic nature of computing infrastructure, has necessitated the need for clear distinctions between the various types of grid systems. This is particularly important when evaluating real-life applications using simulation environments. The very knowledge of what simulation environment to use in evaluating the performances of different types of grid models will go a long way in helping to arrive at a true representation of the system studied. Equally important is the need to identify distinctively the different real life works scenarios, in which these systems are applied. The grid industry is endowed with powerful simulation tools to enable researchers evaluate their designs prior to actual implementations. However, often researchers get busy developing extended versions of these simulators, at the expense of the precious time needed to solve the problem at hand, which is partly due to the wrong choice of simulation environment. This study is inspired by the need to compare and contrast between the two major grid types (Computational and Data Grids) in terms of areas of applications and the simulation environment appropriate for performance evaluation relating to each of these grid systems. This will help researchers to making an informed decision while considering simulation environments to be used in their projects, and help identify the relevant as well as suitable measurable metrics. In addition, the research findings will help to eliminate ambiguity while testing real life applications, and reduces inconsistency in the obtained results.'),(25,'Ghazali, Osman','https://www.scopus.com/authid/detail.uri?authorId=55953618400','Academic Certificates are a social convention that offers a forum for new knowledge about a person or an entity to be transmitted. Academic certificates are one of the areas of education in which the short-term application of blockchain technology can be seen. The practice of certificate fraud is common, undermining investment and trust in higher education systems and bearing substantial economic and social. Falsified qualifications vary from diplomas in high school to doctoral degrees. In addition, the credentials of several famous universities have been forged and it is very difficult to detect such forgeries. Hence, blockchain was introduced to improve the verification process of academic certificates. Recently, blockchain technology has emerged as a potential way of authenticating the process of document authentication and as an effective tool for combating document fraud and misuse. Blockchain based applications have been developed by various Universities. However, privacy preserving was a challenge in most of the existing solutions. Privacy indicates that the certificate protects both identity and information. Therefore , a new Decentralized Certification Verification Privacy Control Protocol is proposed. The proposed protocol can be used for issuing and verifying educational certificates while maintaining privacy and confidentiality at the network level (Ministries level, Universities level, Students level) and data level. The decentralized solution was implemented using Hyperledger Fabric as the infrastructure and Javascript as the contract language. The design of next Vehicular Ad-hoc Network (VANET) in various technologies will offer seamless connectivity across different coverage. However, VANETâ€™s vertical handover (VHO) decision in seamless connectivity is a huge challenge caused by the network topology complexity. Furthermore, the conventional scheme only uses a received signal strength as a metric value, which shows a lack of appropriate handover metrics that is more suitable in horizontal handover compared to VHO. This study aims to design an intelligent network to minimize the handover delay and latency, and packet loss in the heterogeneous Vehicle-to-Infrastructure (V2I) wireless networks. The proposed intelligent-based scheme uses Fuzzy Logic (FL) that generates multiple attributes parameters using the information context of vertical handover decision in the V2I heterogeneous wireless networks. This study uses a network simulator as the mobility traffic network and vehicular mobility traffic generator to perform a topology in a realistic VANET mobility scenario via Wi-Fi, WiMAX, and LTE networks technologies. The proposed intelligent scheme shows an improvement in the QoS handover over the conventional (RSS-based) scheme with an average QoS increased of 21%, 20%, and 13% in delay, latency and packet loss, while Media Independent Handover based (MIH-based) scheme with 12.2%, 11%, and 7% respectively. The proposed scheme assists the mobile user enhanced the QoS handover during the vehiclesâ€™ movement without degrading the performance of ongoing applications. Fueled by the wide interest for achieving rich-storage services with the lowest possible cost, cloud computing has emerged into a highly desired service paradigm extending well beyond Virtualization technology. The next generation of mobile cloud services is now manipulated more and more sensitive data on VM-based distributed applications. Therefore, the need to secure sensitive data over mobile cloud computing is more evident than ever. However, despite the widespread release of several cloud simulators, controlling user\'s access and protecting data exchanges in distributed mobile applications over the cloud is considered a major challenge. This paper introduces a new NetworkCloudSim extension called SecNetworkCloudSim, a secure mobile simulation tool that is deliberately designed to ensure the preservation of confidential access to data hosted on the mobile device and distributed cloud\'s servers. Through high-level mobile users\' requests, users connect to an underlying proxy, which is considered an important layer in this new simulator, where users perform secure authentication access to cloud services, allocate their tasks in secure VM-based policy, manage automatically the data confidentiality among VMs and derive high efficiency and coverage rates. Most importantly, due to the secure nature of proxy, user\'s distributed tasks can be executed without alterations on different underlying proxy\'s security policies. We implement a scenario of follow-up healthcare distributed application using the new extension. Document verification is a complex domain that involves various challenging and tedious processes to authenticate. Moreover various types of documents for instance banking documents, government documents, transaction documents, educational certificates etc. might involve customized verification and authentication practices. The content for each type vary significantly, hence requires to be dealt in a distinct manner. For students, educational certificates are the most important documents issued by their universities. However, as the issuing process is not that transparent and verifiable, fake certificates can be easily created. A skilfully generated fake certificate is always hard to detect and can be treated as the original. With the increase of forged documents, credibility of both the document holder and the issuing authority is jeopardized. Blockchain technology has recently emerged as a potential mean for authenticating the document verification process and a significant tool to combat document fraud and misuse. This research aimed to enhance the document verification process using blockchain technology. In this research, authors have identified the security themes required for document verification in the blockchain. This research also identifies the gaps and loopholes in the current blockchain based educational certificate verification solutions. At the end, a blockchain based framework for verifying educational certificates focusing on themes including authentication, authorization, confidentiality, privacy and ownership is proposed using the Hyperledger Fabric Framework.'),(26,'Yusof, Shahrul Azmi Mohd','https://www.scopus.com/authid/detail.uri?authorId=55975569400','The performance of Multinomial Logistic Regression (MLR) is highly dependent on the estimated value of its parameters (Regression Coefficients - RCs). However, the usual maximum likelihood estimation (MLE) approach of RCs mostly resulted in overfitting the regression model, especially in limited data. Hence alternatives approach (shrinkage) such as Lasso and ridge were proposed. The shrinkage process at times might eliminate important predictors by shrinking the RCs values to zero. We proposed data splitting and swapping approach aimed at eliminating the identified problems in the existing estimation approaches while improving the performance of MLR. Two algorithms were implemented for determining the best set of RCs (DBRCs) which are DBRCs-I and DBRCs-II. Experimental results show that one of the approach- DBRCs-II outperforms the conventional MLE, approach by 2.05 % in overall recognition of Malay vowels. Given enough data for training, DBRCs-I swapping techniques can be use as good technique to obtain good RCs faster. Anxiety is an aversive motivational state that occurs when an individual perceives threat at events. This condition creates harmful effects for candidates during interview sessions. An interviewee overwhelmed in such a state deploys worry as a resource to cope with the threat hence losing the ability to present the self positively for favourable assessments. Most of the digital approaches to assist interviewees in this condition are focused on coaching of verbal and non-verbal cues. The aspect of understanding interviewees\' psychological complexities that influence their behavioural tendencies is lacking in these approaches. As the first step in building an intelligent digital based therapy platform to overcome this issue, this article provides a building block to understanding the interviewees\' anxiety state by means of a computational model. This model is developed based on the conceptual model derived from generalized anxiety disorder theories. The formal model is evaluated using mathematical analysis to determine possible equilibria state and the simulation results are tested against known cases in the literature. The simulation results showed that the degree of threats perceived at events is based on task demands and the resources to cope. Threat is the building block of anxiety through worry which is controlled by one\'s personality and inherent trait anxiety. The results conform to established facts in the literature. Consequently, this model can serve as a basis to build an integrated interviewee mental state model embedded with self-efficacy and motivation constructs as a holistic approach to support interviewees in coaching environments during simulated training. This paper presents a formal analysis approach for self-efficacy model of interviewee\'s mental state during a job interview session. Self-efficacy is a construct that has been hypothesised to combine with motivation and interviewee anxiety to define state influence of interviewees. The conceptual model was built based on psychological theories and models related to self-efficacy. A number of well-known relations between events and the course of self-efficacy are summarized from the literature and it is shown that the proposed model exhibits those patterns. In addition, this formal model has been mathematically analysed to find out which stable situations exist. Finally, it is pointed out how this model can be used in a software agent or robot-based platform. Such platform can provide an interview coaching approach where support to the user is provided based on their individual metal state during interview sessions. This paper is on agent based model of interview motivation to be integrated in a mental constructs model which serves as a basic mechanics for an intelligent virtual agent coaching for job interview. It has been hypothesized that interview motivation combines with self-efficacy and anxiety to define the mental state of a job interviewee. The concepts were modeled based on psychological theories defining human mental state in a time bounded tasking situation like job interview. The proposed model was formalized and simulated to according to its temporal behaviours. The results of the simulation conform to patterns of a number of relations and casual effects on motivation identified in literature. Additionally, the formal model has been automatically verified using Temporal Trace Language (TTL) to find out which stable situations exist. Consequently, this model can serve as a platform for designing an intelligent agent that can understand the metal state of the user during job interview coaching session.'),(27,'Kamaruddin, Siti Sakira','https://www.scopus.com/authid/detail.uri?authorId=23389428500','Text is one of the useful knowledge sources of a human. Each element in a text has to be analyzed to identify the piece of information and knowledge. EDU is important for NLP applications that need a smaller unit to process rather than a sentence such as text summarization, information extraction, and question answering. Therefore, EDU can be more appropriated than a sentence to extract knowledge and information from the text. This paper presents a pipeline of the process for Thai EDU segmentation from word segmentation to EDU segmentation. The shallow parser is applied to chunk a non-recursive phrase in a text to reveal partial syntactic information for EDU segmentation. And then, syntactic information is utilized to identify and reconstruct the EDU segmentation in text. From the experiment, the results show that the precision, recall, and F1 score are 0.88865, 0.91577, and 0.90200 respectively. Sentiment analysis has become one of the most common method to classify stock market behaviour. Moreover, sentiment analysis has gained a lot of importance in the last decade especially due to the availability of data from social media such as Twitter. However, the accuracy of stock market classification models is still low, and this has negatively affected the stock market indicators. In this research, a model for GCC stock market classification based on sentiment analysis is constructed. It is designed to enhance the classification accuracy by the incorporation of tweet timestamp and location features, stock market domain expert labelling technique and the construction of a hybrid Naأ¯ve Bayes classifiers to classify the stock market sentiments. The methodology for this research consists of six phases. Data collection, labelling technique, data pre-processing, classification, performance and evaluation, and the final phase is recognition for the stock market behaviour. The model produced a significant result in classifying stock market behaviour with accuracy more than 89%. The model is beneficial for investors and researchers. For investors, it enables them to formulate their plans based on accurate indicators whereby it reduces the risk in decision making. For researchers, it draws their attention to the importance of feature engineering, labelling technique, and the classifiers hybridization in enhancing the classification accuracy. Event Detection (ED) is a study area that attracts the attention of decision-makers from various disciplines in order to help them in taking the right decision. ED has been examined on various text streams like Twitter, Facebook, Emails, Blogs, Web Forums and newswires. Many ED models have been proposed in literature. In general, ED model consists of six main phases: Data collection, pre-processing, feature selection, event detection, performance evaluation and result representation. Among these phases, event detection phase has a vital rule in the performance of the ED model. Consequently, numerous supervised, unsupervised, semi-supervised detection methods have been introduced for this phase. However, unsupervised methods have been extensively utilized as ED process is considered as unsupervised task. Hence, such methods need to be categorized on such a way so it can help researchers to understand and identified the limitations lay in these methods. In this survey, ED models for text data from various Social Network sites (SNs) are analyzed based on domain type, detection methods, type of detection task. In addition, main categories for unsupervised detection methods are explicitly mentioned with revising their related works. Moreover, the major open challenges faced by researchers for building ED models are explained and discussed in detail. The main objective of this survey paper is to provide a complete view of the recent developments in ED field. Hence, help scholars to identify the limitations of existing ED models for text data and help them to recognize the interesting future works directions. The increase of user-generated content (UGC) on the Internet has led previous studies to propose various sentiment analysis approaches to understand public opinion. The primary goal is to enhance engagement through social media by analyzing various feedback. Sentiment analysis is performed based on two approaches i.e. machine learning and lexicon-based. Since approaches based on machine learning require costly preparation of training dataset and the approaches based on lexicon produce unsatisfactory performance, in this paper, both approaches are combined to perform sentiment analysis on Facebook comments. The importance of a lexicon-based approach to automatically construct the labeled data for machine learning sentiment classification is discussed in this paper. Experiments performed using the Universiti Utara Malaysia (UUM) Facebook posts show that using the combined lexicon-based and machine learning approach on two classifiers i.e. Naأ¯ve Bayes and Support Vector Machine outperform the single approaches to produce more accurate sentiment classifications.'),(28,'Yusof, Yuhanis','https://www.scopus.com/authid/detail.uri?authorId=57068283500','Although numerous methods of using microarray data analysis for classification have been reported, there is space in the field of cancer classification for new inventions in terms of informative gene selection. This study introduces a new incremental search-based gene selection approach for cancer classification. The strength of wrappers in determining relevant genes in a gene pool can be increased as they evaluate each possible geneâ€™s subset. Nevertheless, the searching algorithms play a major role in geneâ€™s subset selection. Hence, there is the possibility of finding more informative genes with incremental application. Thus, we introduce an approach which utilizes two searching algorithms in geneâ€™s subset selection. The approach was efficient enough to classify five out of six microarray datasets with 100% accuracy using only a few biomarkers while the rest classified with only one misclassification. Advertisement on products or services can be found in many forms; video, banners, pamphlets, etc. However, these advertisements only function as a one-way communication as consumers are only presented with the product information and the seller. Further action on purchasing the product is absent or is to be made separately. Such an approach may not guarantee a sale for the seller as the customer may only retrieve the information of the product but purchase it elsewhere. Hence, this study demonstrates the use of QR code technology not only in marketing but also in e-commerce. The technology is realized in â€œOn the GoShopâ€‌ mobile application that has two types of users: seller and buyer. Sellers are people who wanted to promote their product and/or services while buyers are the ones who have a desire to purchase. An evaluation study on the acceptance of the mobile application was then performed on a total of 50 respondents and it is learned that the proposed e-commerce application is well accepted. Ninety percent of the respondents agree with the usefulness of the application and are looking forward to using the application in daily routines. The use of QR code technology not only facilitates consumer in purchasing their desired product but also contribute to cost-effective marketing. Feature selection is a challenging task, specifically in achieving an optimal solution. This is due to the difficulties in choosing the most suitable feature selection method as they tend to work individually and cause incorrect feature selection, which in turn affect the classification accuracy. The objective of this research was to utilise the potential of ensemble methods (boosting) with bio-inspired techniques in improving the performance of multi-objective algorithms (ENORA and NSGA-II) in term of optimum features set. The vital stage in this research was the optimisation of both algorithms using suitable bio-inspired search algorithms with an ensemble method. The next step was the confirmation of the optimal selected feature set by performing a classification task. The evaluation metrics were determined based on the number of selected features with good classification accuracy. Eight benchmark datasets with various sizes were carefully chosen to experiment. Experimental results revealed that both algorithms that used the selected bio-inspired search algorithms with an ensemble method have successfully achieved a better solution with an optimum set of features, that is, less number of features with higher classification accuracy on the selected datasets. This discovery implies that the combination of bio-inspired algorithms with an ensemble method (boosting) improves the performance of both algorithms in attribute selection and classification task. '),(29,'Katuk, Norliza','https://www.scopus.com/authid/detail.uri?authorId=16642395300','Purpose: Many REpresentational State Transfer (RESTful) Web services suffered from anti-patterns problem, which may diminish the sustainability of the services. The anti-patterns problem could happen in the code of the programme or the uniform resource identifiers (URIs) of RESTful Web services. This study aims to address the problem by proposing a technique and an algorithm for detecting anti-patterns in RESTful Web services. Specifically, the technique is designed based on URIs parsing process. Design/methodology/approach: The study was conducted following the design science research process, which has six activities, namely, identifying problems, identifying solutions, design the solutions, demonstrate the solution, evaluation and communicate the solution. The proposed technique was embedded in an algorithm and evaluated in four phases covering the process of extracting the URIs, implementing the anti-pattern detection algorithm, detecting the anti-patterns and validating the results. Findings: The results of the study suggested an acceptable level of accuracy for the anti-patterns detection with 82.30% of precision, 87.86% of recall and 84.93% of F-measure. Practical implications: The technique and the algorithm can be used by developers of RESTful Web services to detect possible anti-pattern occurrences in the service-based systems. Originality/value: The technique is personalised to detect amorphous URI and ambiguous name anti-patterns in which it scans the Web service URIs using specified rules and compares them with pre-determined syntax and corpus. Citations have been an acceptable journal performance metric used by many indexing databases for inclusion and discontinuation of journals in their list. Therefore, editorial teams must maintain their journal performance by increasing article citations for continuous content indexing in the databases. With this aim in hand, this study intended to assist the editorial team of the Journal of Information and Communication Technology (JICT) in increasing the performance and impact of the journal. Currently, the journal has suffered from low citation count, which may jeopardise its sustainability. Past studies in library science suggested a positive correlation between keywords and citations. Therefore, keyword and topic analyses could be a solution to address the issue of journal citation. This article described a scientometric analysis of emerging topics in general computer science, the Scopus subject area for which JICT is indexed. This study extracted bibliometric data of the top 10% journals in the subject area to create a dataset of 5,546 articles. The results of the study suggested ten emerging topics in computer science that can be considered by the journal editorial team in selecting articles and a list of highly used keywords in articles published in 2019 and 2020 (as of 15 April 2020). The outcome of this study might be considered by the JICT editorial team and other journals in general computer science that suffer from a similar issue. Fingerprint is a reliable user authentication method as it is unique to individual users that makes it efficient for authenticating users. In a fingerprint authentication system, user fingerprint information is stored in databases in an image format known as a fingerprint template. Although fingerprint is reliable, the templates stored in the database are exposed to security threats either during the data transmission process over the network or in storage. Therefore, there is a need to protect the fingerprint template, especially in unsecured networks to maintain data privacy and confidentiality. Many past studies proposed fingerprint template protection (FTP) using chaotic-based encryption algorithms that are more suitable to secure images than conventional encryption such as DES, AES, and RSA. The chaotic-based encryption algorithms have been improved a lot in terms of their robustness. However, the robustness of the algorithm caused a trade-off to encryption speed where it remains an issue in FTP. Hence, this study aims to improve the limitations found in the existing chaotic-based encryption algorithms for FTP by improving its encryption speed using Henon and Logistic map. A series of simulations were conducted using MATLAB to evaluate the performance of the proposed chaotic-based encryption algorithm for FTP through different analyses covering key sensitivity, histogram, correlations, differential, information entropy, and encryption/decryption speed. The performance proposed encryption algorithm was promising which could be a starting point for detailed analysis and implementation in real application domains.'),(30,'Yusop, Nor Iadah','https://www.scopus.com/authid/detail.uri?authorId=16644211500','Community cohesion is a very broad concept which means either the process or the state in which a better relationship is established or encouraged between people of different backgrounds, not only in the physical community, but also in the virtual community. The dramatic increase in the number of social media users, especially Facebook, provides some indication that in the lives of many people, virtual community is very vital. If it can be used as a platform for nurturing or inculcating community cohesion, the benefits of virtual community can be further exploited. Somehow a model to measure community cohesion is yet to be devised. Hence, this paper aims to present the transition of the physical to virtual community cohesion model. This process began with the development of the cohesion model of the physical community. Next, the model was reviewed against the virtual community characteristics to determine its relevance for measuring virtual community cohesion. The findings suggest that of the nine physical community cohesion constructs found for the model, only eight are pertinent to virtual community. Smart Tailor is an architecture that integrates various stakeholders such as tailors, designers, and customers in a garment industry. The architecture provides the ability to promote, manage and fulfill supply and demands of their product via electronic ways. Currently, the implementation of the related transaction processes is done manually which may cause time consuming and inefficiency in fulfilling the supply and demands of the garment products. Therefore, this paper aims to construct a conceptual model of Smart Tailor Architecture. This study adopted the first phase of the Rational Unified Process approach, Inception, by identifying the goal of the conceptual model and the verified requirements of the Smart Tailor architecture. Then, the verified requirements were transformed into the Smart Tailor components using the Unified Modeling Language approach. Finally, the verified components by experts become a conceptual model of the Smart Tailor Architecture. The model may contribute to the garment industry stakeholders as well as researchers, decision makers, and software developers. Practitioners in the Malaysian fashion and garment industry, particularly, tailors and fashion designers are facing various challenges in satisfying the supply and demands of their garment products because of them are still providing their products and services through traditional ways. In order to sustain their businesses and remain competitive, they need to transform their current practice in fulfilling customers\' demands. In tackling this issue, this paper presents a reference model of Smart Tailor application for the garment industry practitioners. This is proposed to help reduce the time and increase the efficiency in the fulfilment of the clothing supply and demand. The study adopted the Inception and Elaboration phases of the Rational Unified Process (RUP) in developing the reference model. Starting with the Inception phase, the goal and business requirements were identified using the business model canvas approach, whilst the list of requirements was verified. In the Elaboration phase, the list of requirements was transformed into Smart Tailor design components using the Unified Modelling Language approach. Finally, the verified requirements and design components become a Reference Model of Smart Tailor for garment industry practitioners. The reference model may contribute to garment industry practitioners such as software developers, tailors, and fashion designers as well as to researchers and decision makers in the garment industry domain.'),(31,'Taâ€™a, Azman','https://www.scopus.com/authid/detail.uri?authorId=57210192762','The traditional approach for monitoring chronic diseases represents a major challenge for hospitals and the Ministry of Health in Yemen. This research aims to develop a Remote Patient Health Monitoring System (RPHMS) using Bluetooth enabled medical sensors and mobile phones. This research adopts the Rational Unified Process (RUP) is a software development process framework to develop the proposed system. The RPHMS provides real-time monitoring for the patients suffering from chronic diseases and manages the patients\' medical record in which the diagnostic and prescriptive data are stored for further analysis. The RPHMS consists of two major subsystems: Mobile Patient System (MPS) to wirelessly measure the patient\'s medical and position data, and automatically send the data to the central hospital server; and Central Hospital System (CHS) to automatically store the diagnostic data in the hospital database and then forward the data in form of Short Message Service (SMS) to the doctor. In addition, the CHS enables the patient to get feedback from the doctor. Moreover, CHS stores the feedback and the prescriptions in the hospital database. These data can be accessed by the patient using a mobile application. The results show that RPHMS enables hospitals and doctors to obtain accurate and timely data regarding patients\' chronic illnesses. This research concludes that the RPHMS improves the control of the heart rate, blood pressure, and oxygen percentage in the blood (SPO2), since it provides real-time monitoring of chronic patients. Social media plays an important role in marketing specifically in digital marketing. Many entrepreneur and businesses start to promote their brand and items on the social media platform such as Instagram. The main objective of this study is to crawl data from Instagram and perform some simple analysis to get some entrepreneurial ideas. A system named Graduate Entrepreneur Opportunity Recognition System (GEORsys) is proposed in this study. Hashtags for custom words or sectors like agriculture, services, food and beverages (F&B), fashion, information, communication and technology (ICT) and logistics are used to crawl data from Instagram. Then, some simple visualizations are shown to conclude what keywords or hashtags are popular in Instagram. Generally, a reliable method of analysing the quality of experience is through the subjective method, which is time consuming, lacks usability, lacks repeatability in real-time and near real-time. Another method is the objective measurement that aims at predicting the subjective measurement based on the estimated mean opinion score. Therefore, this study adopted the objective measurement by implementing a quality of experience framework, which employed predictive analytics techniques to analyse the mobile internet user experience dataset gathered through the mobile network. The predictive analytics employed the use of multiple regression, neural network, decision trees, random forest, and decision forest to predict the mobile internet perceived quality of experience. Result from the study shows that decision forests perform better than other algorithms used for the predictive analytics. In addition, the result indicates that the predictive analytics can be used to enhance the allocation of network resources based on location and time constituted in the dataset.'),(32,'Mahmuddin, Massudi','https://www.scopus.com/authid/detail.uri?authorId=37081503400','In reality, students learn via eLearning (electronic online learning) system in different ways depending on their learning needs, learning behaviours as well as eLearning system policy for users. However, most learning outcome prediction models of eLearning systems are still not stable and still cannot be applied in many situations as the use of eLearning is considered to be highly dynamic. Therefore, the objective of this work is understand if eLearning system can be predicted based eLearning usage by exploiting Moodle log data. To understand it, features from web log course-student in Moodle is being considered, a number of machine learning techniques also have been applied for benchmarking in this study. The result found that the current group doesn\'t give better understanding and significant groups of factors that could be able to predict the learning outcome. Investigating the mobile cloud environment is a challenging task due to the characteristics of voluminous data, dispersion of data, virtualization, and diverse data. Recent research works focus on applying the latest forensic methodologies to the mobile cloud investigation. This paper proposes an enhanced forensic examination and analysis model for the mobile cloud environment that incorporates timeline analysis, hash filtering, data carving, and data transformation sub-phases to improve the performance of the cloud evidence identification and overall forensic decision-making. It analyzes the timeline of events and filters the case-specific files based on the hash values and metadata using the data mining methods. The proposed forensic model performs the in-place carving on the filtered data to guide the investigation and integrates the heterogeneous file types and distributed pieces of evidence with the assistance of the data mining. Finally, the proposed approach employs LSTM based model that significantly improves the forensic decision making. The increased utilization of Mobile Cloud Computing (MCC) technology creates an opportunity for cybercrimes. Modeling the suitable methods for mobile cloud forensic examination and analysis is essential to improve the investigation performance. This paper incorporates data mining and optimization methods to enforce precise handling of the mobile cloud evidence in examination and analysis to improve the investigation performance. It enhances the analysis of the mobile cloud forensics with the incorporation of the evidence indexing, cross-referencing, and keyword searching as the sub-processes. The proposed Forensic Examination and analysis methodology using the Data mining and Optimization (FEDO) approach examines the key features of the evidence and indexes the pieces of evidence with key features to facilitate the investigation over the massive cloud evidence. By analyzing the temporal and geo-information, it applies cross-referencing to alleviate the evidence toward the case-specific evidence. The proposed methodology improves the searching capability of the investigation through the Linearly Decreasing Weight (LDW) strategy based Particle Swarm Optimization (PSO) algorithm. Thus, the experimental results demonstrate that the proposed forensic methodology yields better investigation performance in terms of accuracy of evidence detection. The increased number of computers, enlarged network bandwidth, more powerful computers, consumed resources and the acceptance of the Internet has driven the ongoing demand for new and better ways to execute huge problems in shared computing infrastructure such as grid and P2P computing. Resource discovery is extremely significant and challenging issues in Grid and P2P. It is complex because resources are heterogeneous, dynamic, geographically distributed, manageability and autonomous. A well-organized resource discovery mechanism is the fundamental requirements for resource sharing infrastructure, as it supports and facilities the resource administration and scheduling of applications. In computing systems like Grid, provide many resources across multiple administrative domains for the achievement of the goal. The major challenge faced by the system is to find the right resources on the network. In this paper, we study the resource discovery mechanisms that have been used in distributed computing systems so far. The mechanism for discovery of resource is divided into different types: centralized, decentralized, and hierarchical. We review the main developments in these categories and outline the new challenges. This paper also provides a discussion of the differences between the mechanisms considered for scalability, dynamism, reliability and real consultations as well as directions for future research.'),(33,'Hashim, Nor Laily','https://www.scopus.com/authid/detail.uri?authorId=16052739400','The objective of this paper is to examine the level of readiness among Dubai citizens to adopt Dubai Smart Government services using the new emerging technologies. This study adopts the Technology Readiness theory as the underlying factor predicting the citizen\'s intention to adopt the e-government services. An online survey was conducted and 225 respondents replied to it. The data were analyzed using a structural equation modeling technique. The results show that a citizen\'s intention to adopt e-government  services using the new technologies are strongly influenced by their level of the service\'s innovativeness and security. Meanwhile, the feeling of discomfort negatively influenced their intention to adopt e-government services. This paper ends by discussing the theoretical and practical contributions of this study. Usability evaluation is a process that accesses any system or application functions and user experience on it. Deaf users are usually isolated when it comes to mobile applications because they are disabled. The usability evaluation model for the mobile application for deaf people is developed to meet the needs of deaf people in any application for better user experience. This paper presents the empirical findings of usability testing conducted with the deaf user. The result shows that the model used in usability testing allows the potential user to identify usability issues and provide insights into the application\'s real need. Despite continuous effort in test case generation in UML diagrams, especially UML statecharts, there are inconsistencies in the processes used in this domain that have raised needs for a framework that will have a complete set of process to generate test cases. As a prerequisite for creating this framework and to better understand the existing processes used in test case generation, a review on existing work in this domain was conducted to discover the current methods, types of coverage criteria and types of evaluation conducted to evaluate test cases quality. The review was conducted on 24 existing work in test case generation using UML statecharts using content analysis method. The results revealed that most of the work in this domain, translated the UML statechart diagram into an intermediate model. Among the common algorithm for establishing test cases is Depth First Search. Furthermore, this review emphasizes the importance of achieving all-state coverage and all-transaction coverage in conducting coverage criteria. This study is aimed to explore the dimensions for appropriate deaf people usability evaluation model for M-banking application in order to enhancetheir satisfaction. Through the systematic literature review (SLR) conducted, four dimensions (efficiency, effectiveness, satisfaction and accessibility) have been identified to be appropriate to suit the need of m-banking application usability evaluation especially for the deaf people. Furthermore, innovation and technologies through digital economy are practical and aptly accessible to allows persons who are deaf to fully participate in society, education, and business while also providing prospects for personal and professional advancement. Moreover, this study will be able to provide recommendation to the upper management of Malaysia Banks to concern on mobile services in order to enhance the deaf customers\' satisfaction. Financial and economy implications together with future research suggestions are also discussed in this study.'),(34,'Ahmad, Farzana Kabir','https://www.scopus.com/authid/detail.uri?authorId=57218092556','Multi-label classification is a general type of classification that has attracted many researchers in the last two decades due to its applicability to many modern domains, such as scene classification, bioinformatics and text classification, among others. This type of classification allows instances to be associated with more than one class label at the same time. Class label ranking is a crucial problem in multi-label classification research, because it directly impacts the performance of the final classifiers, as labels with high ranks get a higher chance of being applied. This paper presents a new multi-label ranking algorithm called Multi-label Ranking based on Positive Correlations among labels (MLR-PC). MLR-PC captures positive correlations among labels to reduce the large search space and assigns the true rank per class label for multi-label classification problems. More importantly, MLR-PC utilizes novel problem transformation methods that facilitate exploiting accurate positive correlations among labels. This improves the predictive performance of the classification models derived. Empirical results using different multi-label datasets and five evaluation metrics reveal that the MLR-PC is superior to other commonly existing classification algorithms. Text is one of the useful knowledge sources of a human. Each element in a text has to be analyzed to identify the piece of information and knowledge. EDU is important for NLP applications that need a smaller unit to process rather than a sentence such as text summarization, information extraction, and question answering. Therefore, EDU can be more appropriated than a sentence to extract knowledge and information from the text. This paper presents a pipeline of the process for Thai EDU segmentation from word segmentation to EDU segmentation. The shallow parser is applied to chunk a non-recursive phrase in a text to reveal partial syntactic information for EDU segmentation. And then, syntactic information is utilized to identify and reconstruct the EDU segmentation in text. From the experiment, the results show that the precision, recall, and F1 score are 0.88865, 0.91577, and 0.90200 respectively.  Motion trajectory prediction is one of the key areas in behaviour and surveillance studies. Many related successful applications have been reported in the literature. However, most of the studies are based on sigmoidal neural networks in which some dynamic properties of the data are overlooked due to the absence of spatiotemporal encoding functionalities. Even though some sequential (motion) learning studies have been proposed using spatiotemporal neural networks, as in those sigmoidal neural networks, the approach used is mainly supervised learning. In such learning, it requires a target signal, in which this is not always available in some applications. For this study, motion learning using spatiotemporal neural network is proposed. The learning is based on reward-modulated spike-timing-dependent plasticity (STDP), whereby the learning weight adjustment provided by the standard STDP is modulated by the reinforcement. The implementation of reinforcement approach for motion trajectory can be regarded as a major contribution of this study. In this study, learning is implemented on a reward basis without the need for learning targets. The algorithm has shown good potential in learning motion trajectory particularly in noisy and dynamic settings. Furthermore, the learning uses generic neural network architecture, which makes learning adaptable for many applications.'),(35,'Hussein, Idyawati','https://www.scopus.com/authid/detail.uri?authorId=35484164200','This research report provides an intuitive insight into the design goals, practice values and the motivations why practitioners involved in a community of practice are motivated to practice user experience design in industry. A survey approach with instrument having closed ended questions was utilized. The results indicated that the practitioners\' design goals followed a hierarchy, in the order: usability, functionality, security, pleasure and customizability. The strongest motivation driving respondents who attended the user experience (UX) gathering was performance oriented, hingedon classic competitiveness. In addition, the highest values among the respondents (UX designers) were to make users happy, followed by a focus on clients\' happiness. This study reports on the research involving the use of a participant observation approach to understand the characteristics of UX Malaysia, a community of practice for user experience design (UXD). This qualitative approach provides insight into the behaviour, characteristics and attitude of the members of the community of practice which they may not express when other research approaches are used. The results reveal deep insight about the characteristics of the observed community of practice. This study reports on the research involving the use of a participant observation approach to understand the characteristics of UX Malaysia, a community of practice for user experience design (UXD). This qualitative approach provides insight into the behaviour, characteristics and attitude of the members of the community of practice which they may not express when other research approaches are used. The results reveal deep insight about the characteristics of the observed community of practice. This research report provides an intuitive insight into the design goals, practice values and the motivations why practitioners involved in a community of practice are motivated to practice user experience design in industry. A survey approach with instrument having closed ended questions was utilized. The results indicated that the practitionersâ€™ design goals followed a hierarchy, in the order: usability, functionality, security, pleasure and customizability. The strongest motivation driving respondents who attended the user experience (UX) gathering was performance oriented, hingedon classic competitiveness. In addition, the highest values among the respondents (UX designers) were to make users happy, followed by a focus on clientsâ€™ happiness.'),(36,'Bakar, Juhaida Abu','https://www.scopus.com/authid/detail.uri?authorId=57195694021','Leukemia is a type of cancer that affects the white blood cell. Early detection of leukemia is important to reduce the rate of mortality. In order to detect acute leukemia, conventional screening method based on microscopic image is used, where sample of blood cell will be taken from the suspected leukemia patient and manually white blood cell (WBC) condition is observed using microscope. The manual screening process is tedious, time consuming and usually prone to error due to low contrast between the nucleus and cytoplasm of WBCs. This report introduces a new enhancement method which is a combination of Particle swarm optimization (PSO) algorithm and contrast stretching, known as Hybrid PSO-Contrast stretching (HPSO-CS). The PSO has been used to optimize the fitness criterion in order to improve the contrast and detail in microscopic image by adapting the parameters as a contribution to enhancement technique. In this study, PSO algorithm is used to perform image segmentation to remove all the unwanted part such as red blood cell (RBC), platelet and also the background while retain the WBC part. The segmentation algorithm uses saturation S-component based on Hue, Saturation, Intensity (HSI) color model. After the segmentation is done, contrast stretching process is applied to the original image to stretch intensity of the pixel. Then the segmented image is combined with the resultant image that has been stretched to produce the enhanced image. The results of the proposed method are evaluated by using mean-square error (MSE), Peak-signal-to-noise-ratio (PSNR) and Absolute mean brightness error (AMBE). This proposed method is benchmarked by comparing against two image enhancement methods, global enhancement and Class Limited Adaptive Histogram Equalization (CLAHE). Based on the results, it can be concluded that quality of the enhanced image for the proposed method is much better with the lowest MSE (2067.651), AMBE (43.51827) and highest PSNR (14.98671) compared to the global and CLAHE method. The proposed method can improve the screening process and assist haematologist in leukemia screening and detection by improving the visual appearance of the WBC. Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur\'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur\'an corpus.'),(37,'Omar, Mohd Nizam Bin','https://www.scopus.com/authid/detail.uri?authorId=57217535319','Adoption and use of technology services can contribute positively to development. However, many developing nations, such as Iraq, have not been qualified to exploit advantages of these services. E-government projects are still inadequate in this country. Scientific research that attempts to solve e-government problems is lacking. This research objective is to identify and evaluate the factors that drive an employee\'s decision to accept or reject e-government services in the Iraqi public sector. The sample consisted of employees of the Department of Education of Suq Al-Shuyuk, in Southern Iraq. The questionnaires were distributed to 300 employees, but only 273 responses were collected. Extended technology acceptance model and SPSS were employed to conduct statistical analyses for the factors chosen based on earlier studies and related works. The outcomes showed that trust on the internet and perceived usefulness strongly affect employee acceptance, whilst trust in the government has less effect. Nowadays, communication is very important between people because through communication we can exchange knowledge, share ideas and experience with friends. Communication plays a fundamental role in many situations to full fill our needs or tasks. At present, there are a lot of apps that are being used by people for communication, but all these apps need Wi-Fi or mobile data which is not always available and have to pay a related cost. As a solution to this problem, Bluetooth chat app has existed for free of cost and that doesnâ€™t need WI-FI or mobile data to communicate. But this Bluetooth chat app has not existed on wear OS. Therefore, the Bluetooth chat app was developed on wear OS in order to have quick communication with each other without taking out their phones from their bag or pocket. The method to develop this project is the prototyping model. The field study that was carried out an evaluation method that is usability evaluation. The result of the usability evaluation clarifies that Bluetooth chat app for wear OS is useful, easy to use, and help to communicate quickly. The respondents also satisfied with the functions. By using this application, users can exchange short messages, share images and can send voice messages. The study contributes towards an understanding of the system requirements and user interface of a Bluetooth chat app for wear OS. So far, APT (Advanced Persistent Threats) is a constant concern for information security. Despite that, many approaches have been used in order to detect APT attacks, such as change controlling, sandboxing and network traffic analysis. However, success of 100% couldnâ€™t be achieved. Current studies have illustrated that APTs adopt many complex techniques to evade all detection types. This paper describes and analyzes APT problems by analyzing the most common techniques, tools and pathways used by attackers. In addition, it highlights the weaknesses and strengths of the existing security solutions that have been used since the threat was identified in 2006 until 2019. Furthermore, this research proposes a new framework that can be used to repel this threat based on APT activity with network traffic through packets analysis and host destination.'),(38,'Nordin, Noradila','https://www.scopus.com/authid/detail.uri?authorId=57190342007','Attendance marking in a classroom is one of the methods used to track the student\'s presence in the lecture. The conventional method that is being enforced has shown to be vulnerable, inaccurate and time-consuming especially in a large classroom. It is difficult to identify absentees and proxy attendees based on the conventional attendance marking method. In order to overcome the challenges faced in the conventional method, a web-based mobile attendance system with facial recognition feature is proposed. It incorporated the existing mobile devices with a camera and the face recognition system to allow the attendance system to be used in classrooms automatically and efficiently with minor implementation requirements. The system prototype received positive responses from the volunteers who tested the system to replace the conventional attendance marking. This paper proposes a new decentralised multi-channel tree building protocol with a centralised controller for the Internet of Things. The protocol alleviates the effect of interference which results in improved network efficiency and stability, and link reliability. The proposal takes into account all available channels to utilise the spectrum and aims to use the spectrum efficiently by transmitting on several channels. The protocol detects which channels suffer interference and changes away from those channels. The algorithm for channel selection is a two-hop colouring protocol that reduces the chances of nearby nodes to transmit on the same channel. All nodes are battery operated except for the low power border router (LPBR). This enables a centralised channel switching process at the LPBR. The protocol is built based on the routing protocol for low power and lossy networks (RPL). In its initial phase, the protocol uses RPL\'s standard topology formation to create an initial working topology and then seeks to improve this topology by switching channels. The implementation and evaluation of the protocol is performed using the Contiki framework. The experimental results demonstrate an increased resilience to interference and significantly higher throughput making better use of the total available spectrum and link stability.'),(39,'Abai, Nur Hani Zulkifli','https://www.scopus.com/authid/detail.uri?authorId=57110399300','Literature study shows that several works have been conducted on the implementation of BI in performance management, but the analytical aspects were not being considered. Business analytics is an activity of applying analytics to strengthen strategic and operational business activities. While performance management is important to determine organisational success and in public sector, it has become more challenging due to generality of public sector objectives and different level of stakeholders involved. Existing frameworks were built separately and this limits the implementation of Business Intelligence and Analytics as an integrated component, and could not meet the current performance management needs and expectations. The objective of this study is to establish a framework that integrates elements of business intelligence, analytics and performance management for the comprehensive implementation in public sector. This study identifies four main components of this integrated framework: Process, People, Governance and Ability. Each component consists of several key elements and sub-elements. The proposed framework is validated and implemented by real case study conducted in one organisation in Malaysia. The implementation demonstrates the suitability and practicality of this framework to be implemented in real environment. Water is essential in our life and, its availability and quality are critical. Therefore we must preserve and avoid water wastage through effective water management and reduction of water loss. Water leaks usually occur quietly, and this causes a lot of water wastage before we can identify the leakage location. Several methods have been proposed by the previous researcher to solve this issue; however, most of them require high implementation cost and complexity to maintain. This paper discusses the design of an IoT based Smart Water Reticulation Monitoring System that able to provide the remote monitoring of the water reticulation system using mobile application. It uses water pressure sensor with efficient battery management. It also connected to a mobile application for monitoring and received alerts for any leakage. Business intelligence and analytics (BIA) is emerging as a critical area to boost organizational performance. Nowadays, data is not only important and valuable to the organization but recognized as necessary to spike the organization performance and success. As a result, many organizations spend a considerable amount of investment toward obtaining faster accurate information on a real-time basis. The previous study revealed that even though many organizations use business intelligence technologies for obtaining information, yet they still lack analytics implementation. Therefore, this study aims to discover the integrated implementation factors of business intelligence and analytics in managing organizational performance, particularly for organizations of the public sector. In achieving this, a depth literature review was carried out to identify the influential factors in the implementation of business intelligence, business analytics, and performance management. The subject matter experts in Business Intelligence (BI), Business Analytics (BA) and Organisational Performance Management (OPM) were invited to participate in this empirical study, which was conducted in Malaysia. The study was carried out through interviewing experts, in order to identify the essential factors for business intelligence and data analytics implementation. Twenty essential factors and sixty-four sub-factors were identified and analyzed to construct the integrated factors in BIA and OPM implementation. The result of the study revealed four integrated factors of the BIA and OPM implementation, such as skill, documentation, visualization, and work culture. Finance, data management, software, strategic planning, and decision-making are other factors integrated with BI, BA, and OPM respectively. Finally, this study illustrates the integrated factors in a visual form.'),(40,'Ahmad, Rahayu','https://www.scopus.com/authid/detail.uri?authorId=42960896700','The purpose of this study is to investigate the quality design criteria for developing a Massive Open Online Course (MOOC). Currently, there are limited studies that highlight the required design criteria for the MOOC programming courses. A descriptive analysis was conducted to examine the characteristics of the three important quality design criteria which are (i) Instructional Design Criteria involving Lecture Organization and Culture; (ii) Technical Criteria involving User Interface, Video Content, Learning and Social Tools, and Learning Analytics; and (iii) E-Assessment. The data were collected from 306 respondents, representing the UUM MOOC students of 2018 class, were further analyzed using the T-Test hypothesis testing to determine whether both the programming and nonprogramming students require the same quality design criteria. The questionnaire used in this study consists of 46 items related to the MOOC quality design criteria that were adapted from previous studies. The results indicate that out of the nine constructs, four have obtained significant differences in the mean scores, namely the Video Content, Instructional Design, Culture, and E-assessment. This signifies that different quality design criteria are needed for both the programming and nonprogramming students. The outcome of this study may assist the developers in designing the MOOC by providing the required criteria according to its importance. Public health, safety and welfare of community is one of the important sustainable development goals. Basic water supply, electricity and waste disposal must be in optimum condition in promoting quality of life. Citizens need to be afforded with simple and usable system for reporting problems related to the public facilities and services to their local councils. Currently, there is no integrated online mechanism for reporting and monitoring the problems. This study proposes a simple and usable mobile application for reporting known as My Response. Additionally, how usability factors are related to intention of using this apps were analyzed. 40 local people participated in the usability study. Usability attributes accommodated in this application such as the instant start or launch feature, well and comprehensible designed icon positively correlates with intention to use the application. The usage of understandable terminology, concise language and minimal user effort required in MyResponse also positively correlates with intention to use. In our study, simplicity and understandability in using and navigating the apps is the golden rule. Many government agencies have been implementing digital-based public facilities and amenities reporting and management systems. However, these systems need further improvement as there exist some contradictions between the requirements of the rural users and the complex idea of the developer. Exploring the views of rural citizens on these systems, this paper shares some lesson learned from the mobile app development point of view and real user\'s expectations. An Android smart mobile app prototype was developed based on the current requirement of necessary facilities and amenities reporting system. It was then tested by 40 participants from various level of community members in Langkawi Island, based on the specific real reporting scenarios. The overall analysis revealed that rural users prefer simplicity as opposed to the complexity of mobile apps.'),(41,'Mohamed, Shafinah Farvin Packeer','https://www.scopus.com/authid/detail.uri?authorId=55932664000','Technology-mediated assistance in house purchasing decision is evidenced in many developed countries, however, in Malaysia less study was found although the decision challenges faced by first-time homebuyers are undeniable. This study attempts to embed technology assistance in the prominent consumer decision-making process model for the purpose of assisting first time homebuyers to make a house purchasing decision. This study employs mixed method approaches with Klang Valley, Malaysia as case study. 19 housing attributes under Locational, Neighborhood, Structural and Social Cultural group, are surveyed to validate the distinctive nature of the attributes to be part of the decision-making criteria. Factor analysis is performed on 320 data from the potential first-time homebuyers in Klang Valley. Two key factors are confirmed from the analysis; which are needs (i.e. Locational and Structural) and preferences (i.e. Neighborhood and Social Cultural). Both factors are later embedded in the proposed design model of computerized decision aid for homebuyers. The model is then evaluated through expert reviews and data was analysed qualitatively using thematic analysis. Four themes emerged from the analysis, which are Suggestion, Concern, Strength, and Limitation. Meaningful discovery on how would the future applications may have an impact is made through analysing themes with negative connotation like Concern and Limitation. The focused themes also reflect actual insights from the industryâ€™s key players, which are useful for improvement of the proposed design model and towards more effective computerized decision aid for first-time homebuyers. Recently, business transformation towards the used of Information and Communication Technology (ICT) is a necessity toward rapid industries and the paradigm shifted to sustain business competitiveness. The holistic electronic approach is one of business innovations, especially in handling a lot of tender documentations and process in an electronic environment namely as e-Tendering. Unfortunately, the existing tender process transformation in the electronic approach is not properly followed certain standard and guideline, especially in establishing a good e-Tendering functional requirements specification to ensure the organizations would be in the best served. This is important to ensure a good e-Tendering system can be developed by e-Tendering developers based on a good e-Tendering functional requirement specifications. The requirements specification is a process of documenting user and system requirements. Commonly, user and system requirements should be clear, unambiguous, easy to understand, complete, and consistent. In practice, this is difficult to achieve due to interpretation of the requirements in different ways by stakeholders, which are often inherent conflicts and inconsistencies of the requirements. The implementation of the existing e-tendering still remains uncertainties, especially in defining the functional requirements of the e-tendering system. Therefore, this study aims to construct the e-Tendering functional requirement model using requirement template in natural language representation approach. Moreover the development of this system requirement model may provide a consistency to the requirements representation. The study uses UN/CEFACT Business Standard of the e-Tendering Business. The identified functional requirements are designed by using Requirement Template to ensure the reliability and understandability of requirements. Besides, the proposed functional requirements is constructed by adapting the natural language and verified by expert review approaches. As a result, this study proposed a functional requirements specification of the e-Tendering that contains detailed description which can be referred by software practitioners in developing a secure e-tendering system effectively.'),(42,'Din, Aniza Mohamed','https://www.scopus.com/authid/detail.uri?authorId=36998324400','The analyzing and extracting important information from a text document is crucial and has produced interest in the area of text mining and information retrieval. This process is used in order to notice particularly in the text. Furthermore, on view of the readers that people tend to read almost everything in text documents to find some specific information. However, reading a text document consumes time to complete and additional time to extract information. Thus, classifying text to a subject can guide a person to find relevant information. In this paper, a subject identification method which is based on term frequency to categorize groups of text into a particular subject is proposed. Since term frequency tends to ignore the semantics of a document, the term extraction algorithm is introduced for improving the result of the extracted relevant terms from the text. The evaluation of the extracted terms has shown that the proposed method is exceeded other extraction techniques. Forecasting model has been applied in many areas of study. Neural Network (NN) is the most popular forecasting model among the intelligent methods. However, NN had some limitations in learning patterns which have terrific noise and nonlinear characteristic. This paper aims to analyze the performances of NN forecasting model using data that have been smoothed. The actual data were smoothed by three exponential smoothing techniques and normalized before the experiment. One NN model was developed and tested with ten different hidden units. The percentage of correctness and mean absolute error gathered from NN training were used to evaluate the NN performance. The findings show that the NN model using smoothed data gives better performance compared to actual data. Focusing on the use of Semantic Network and Conceptual Graph (CO) representations, this paper presents an easy way in understanding concepts discussed in the Holy Quran. Quran is known as the main source of knowledge and has been a major source reference for ail types of problems. However understanding the issues and the solution from the Quran is difficult due to lack of understanding of Quran literature. Meticulously, the Quran contains much important information related to female. However, this information are scattered and complexly linked. Technically, to extract and present the encapsulated knowledge on female matters in the Quran is a challenging task. Thus, this paper discusses on how to understand and represent the knowledge in an easy way. A total of 18 female terms are identified. Through the terms, the name of surah, verses number and text from the verses are gathered. The texts are then analyzed and clustered into specific issues. Result of the analysis that consists of extracted knowledge on female issues is presented in a systematic structure using Semantic Network and CG. The strength and advantages of both approaches are compared, discussed and presented.'),(43,'Osman, Baharudin','https://www.scopus.com/authid/detail.uri?authorId=36682907600','Quick response (QR) code is a printed code of black and white squares that is able to store data without the use of any of the electronic devices. There are many existing researches on coloured QR code to increase the storage capacity but from time to time the storage capacity still need to be improved. This paper proposes the use of compress, multiplexing and multilayered techniques, as an integrated technique known as CoMM, to increase the storage of the existing QR code. The American Standard Code for Information Interchange (ASCII) text characters are used as an input and performance is measured by the number of characters that can be stored in a single black and white QR code version 40. The experiment metrics also include percentage of missing characters, number of produced QR code, and elapsed time to create the QR code. Simulation results indicate that the proposed algorithm stores 24 times more characters than the black and white QR code and 9 times more than other coloured QR code. Hence, this shows that the coloured QR code has the potential of becoming useful mini-data storage as it does not rely on internet connection. Hiding data in text has always been a challenge due to textual media contains limited redundant space compares to the others media such as image, audio and video. This paper proposed a hiding technique of hidden message at random location using Pseudorandom Number Generator and RGB color. A hidden message has been represented in 3D representation by enhance the equation introduce by the previous study. The result shows that the capacity of hidden message achieves 100%. However the representation of hidden message character shows a similar pattern which can cause the steganalysis to study the pattern of concealment. Steganography is a method of concealing a secret message in a cover medium in such a way that the intruder is not able to detect the existence of the secret message. Due to extensive use of Internet and other communications media, the confidentiality and data integrity need a special means to protect it against unauthorized access. Several schemes were introduced by researchers to represent the value of a hidden message. The first scheme converts a secret message to ASCII code and is represented into x,y form which raises a redundancy representation for a repeating character of the secret message. The second scheme is using the octal value of secret message and converts it into a similar form. Another scheme modifies the previous scheme by adding a \"+\"\" and \"\"-\"\"symbols. These techniques are resulted in the limited range of the x'),(44,'Arif, Suki M.A.','https://www.scopus.com/authid/detail.uri?authorId=55838016000','The ever increasing need for grid systems in scientific, business and â€œwhat ifâ€‌ real world types of applications, coupled with the dynamic nature of computing infrastructure, has necessitated the need for clear distinctions between the various types of grid systems. This is particularly important when evaluating real-life applications using simulation environments. The very knowledge of what simulation environment to use in evaluating the performances of different types of grid models will go a long way in helping to arrive at a true representation of the system studied. Equally important is the need to identify distinctively the different real life works scenarios, in which these systems are applied. The grid industry is endowed with powerful simulation tools to enable researchers evaluate their designs prior to actual implementations. However, often researchers get busy developing extended versions of these simulators, at the expense of the precious time needed to solve the problem at hand, which is partly due to the wrong choice of simulation environment. This study is inspired by the need to compare and contrast between the two major grid types (Computational and Data Grids) in terms of areas of applications and the simulation environment appropriate for performance evaluation relating to each of these grid systems. This will help researchers to making an informed decision while considering simulation environments to be used in their projects, and help identify the relevant as well as suitable measurable metrics. In addition, the research findings will help to eliminate ambiguity while testing real life applications, and reduces inconsistency in the obtained results. The increased number of computers, enlarged network bandwidth, more powerful computers, consumed resources and the acceptance of the Internet has driven the ongoing demand for new and better ways to execute huge problems in shared computing infrastructure such as grid and P2P computing. Resource discovery is extremely significant and challenging issues in Grid and P2P. It is complex because resources are heterogeneous, dynamic, geographically distributed, manageability and autonomous. A well-organized resource discovery mechanism is the fundamental requirements for resource sharing infrastructure, as it supports and facilities the resource administration and scheduling of applications. In computing systems like Grid, provide many resources across multiple administrative domains for the achievement of the goal. The major challenge faced by the system is to find the right resources on the network. In this paper, we study the resource discovery mechanisms that have been used in distributed computing systems so far. The mechanism for discovery of resource is divided into different types: centralized, decentralized, and hierarchical. We review the main developments in these categories and outline the new challenges. This paper also provides a discussion of the differences between the mechanisms considered for scalability, dynamism, reliability and real consultations as well as directions for future research. Classical scheduling mechanisms donâ€™t satisfy the requirements for the end user, especially if the number of the jobs has increased massively in grid computing environment. To meet the expectations for non-trivial applications, the efficiency of the system has to be improved and the resources have to be ultimately utilized. Thus, backfilling technique becomes highly required due to its efficiency in exploiting the resources by filling the gaps that was created in the scheduler by short jobs. There are two well-known mechanisms, which are Extensible Argonne Scheduling System (EASY) and Conservative Backfilling (CONS). EASY is very aggressive and well uses the resources, however it causes a delay for the jobs ahead in the queue, while CONS solve this issue at the expense of system efficiency. In addition, and to further improve the scheduling quality, schedule-based approach has to be implemented. This approach provides information for the incoming job parameters and the resources capabilities; thus, the mechanism schedules the jobs in advance. This approach has shown a significant improvement compared with queue-based approach. In this paper, a new mechanism is proposed, namely Swift Gap. This mechanism implements schedule-based approach and applies multi-level scheduling method. In the first stage, the mechanism finds the right place for the newly arrival job, while in the second stage it manipulates the jobsâ€™ positions for further optimization. Moreover, this paper introduces the completion time scheme. This scheme minimizes both start time and processing time. The evaluation has shown the significant impact of Swift Gap alongside the completion time rule compared to CONS and EASY.'),(45,'Abd Wahab, Alawiyah','https://www.scopus.com/authid/detail.uri?authorId=57216343602','The purpose of this study is to investigate the quality design criteria for developing a Massive Open Online Course (MOOC). Currently, there are limited studies that highlight the required design criteria for the MOOC programming courses. A descriptive analysis was conducted to examine the characteristics of the three important quality design criteria which are (i) Instructional Design Criteria involving Lecture Organization and Culture; (ii) Technical Criteria involving User Interface, Video Content, Learning and Social Tools, and Learning Analytics; and (iii) E-Assessment. The data were collected from 306 respondents, representing the UUM MOOC students of 2018 class, were further analyzed using the T-Test hypothesis testing to determine whether both the programming and nonprogramming students require the same quality design criteria. The questionnaire used in this study consists of 46 items related to the MOOC quality design criteria that were adapted from previous studies. The results indicate that out of the nine constructs, four have obtained significant differences in the mean scores, namely the Video Content, Instructional Design, Culture, and E-assessment. This signifies that different quality design criteria are needed for both the programming and nonprogramming students. The outcome of this study may assist the developers in designing the MOOC by providing the required criteria according to its importance. The evolution of Blockchain introduces the first cryptocurrency and continues to attract public attention. Being an open-source project, disagreements among development communities often lead to the loss of committers. The projects always in-search for a new committer to spur innovation but come with hard fork risk. Prior promotion models are based on the developer\'s technical activities. However, there is a lack of academic research that investigates developer commitment. Drawing literature from open-source projects, such as Mozilla, Apache and Social Cognitive Theory, this paper proposes a model that integrate SCT constructs and Blockchain decentralization to examine the factors that influence developer commitment in cryptocurrency project. This study proposes a quantitative approach by collecting data from online survey to evaluate the proposed model using partial least square structural equation modelling (PLS-SEM). This paper is expected to be a valuable contribution to project leaders and community to identify committed developer and antecedent factors. Public health, safety and welfare of community is one of the important sustainable development goals. Basic water supply, electricity and waste disposal must be in optimum condition in promoting quality of life. Citizens need to be afforded with simple and usable system for reporting problems related to the public facilities and services to their local councils. Currently, there is no integrated online mechanism for reporting and monitoring the problems. This study proposes a simple and usable mobile application for reporting known as My Response. Additionally, how usability factors are related to intention of using this apps were analyzed. 40 local people participated in the usability study. Usability attributes accommodated in this application such as the instant start or launch feature, well and comprehensible designed icon positively correlates with intention to use the application. The usage of understandable terminology, concise language and minimal user effort required in MyResponse also positively correlates with intention to use. In our study, simplicity and understandability in using and navigating the apps is the golden rule.'),(46,'Ahmad, Amran Bin','https://www.scopus.com/authid/detail.uri?authorId=55838479700','The manual attendance system is a time- consuming method which creates many difficulties for teachers to record student\'s attendance. Therefore, there is a need for a more convenient biometric student attendance system (SAS) to minimize these difficulties. As face recognition is considered among the best biometric technique, hence face recognition technique is inferential to be used in SAS. The main purpose of this study is to understand the existing works on SAS using face recognition. The current study conducted a survey on previous literature on student attendance system using face recognition. This paper describes the face recognition processes, approaches, and challenges involved in face recognition technique. Illumination in face recognition process has been a challenge in many previous studies. To address this challenge, this study proposed a mobile based SAS by using face recognition technique. The study comes up with a conclusion that face recognition is the most time saving method in SAS that used the mobile camera to resolve the issue of illumination and pose invariance for face recognition in SAS. It was also found that the use of hybrid approach of Principal Components Analysis (PCA) and Linear Discriminant Analysis (LDA) algorithm, increases the accuracy of face recognition in SAS. Named Data Networking (NDN) is a clean-slate future Internet architecture proposed to support content mobility. However, content producer mobility is not supported fundamentally and faces many challenges such as high handoff latency, signaling overhead cost and unnecessary Interest packet losses. Hence, many approaches indirection-based approach, mapping-based approach, locator-based approach and control/data plane-based approach were proposed to address these problems. Mapping-based and control/data plane-based approach deployed servers for name resolution services to provide optimal data path after the handoff, but introduces high handoff latency and signaling overhead cost. Indirection-based and locator-based approach schemes provide normal handoff delay but introduce sub-optimal or triangular routing path. Therefore, there is needs to provide substantial producer mobility support that minimizes the handoff latency, signaling cost and improve data packets delivery via optimal path once a content producer relocates to a new location. This paper proposed a scheme that provides optimal data path using mobility Interest packets and broadcasting strategy. Analytical investigation result shows that our proposed scheme outperforms existing approaches in terms of handoff latency, signaling cost and path optimization. Named Data Networking is a consumer-driven network architecture that supports content consumer mobility due to the nature of in-network catching. The architecture is proposed to supplement and replace current Internet architecture by using named content in place of IP-address. In this paper mobility problem is selected to presents and discussed about the tools necessary for problem investigation in NDN. Usually modeling, simulation and testbed methods are used for investigation of any problem in the field of networking. Analytical investigation and simulation tools are covered, and the investigation can be done using network analysis model with any technique such as hop count method for analytical investigation. While simulators such as ndnSIM, CCNLite, OMNET ++ and ccnSim can be used as tools for simulation.'),(47,'Aziz, Azizi Ab','https://www.scopus.com/authid/detail.uri?authorId=35100067700','Soon, sociable companion robots will become indispensable for providing related support in our daily living and tasks. This paper provides process, design perspectives, and deployment of a reading companion robot (IQRA\') that monitors the cognitive load level of a reader during demanding reading tasks and to provide support for readers to complete tasks. Current technological solutions only cover external design aspects of the application and have no adaptive mechanisms to deal with dynamics with the reader\'s perspectives and environment. Inspired by several theories from cognitive psychology domains, a computational model of the cognitive load was developed as a basis for reasoning and analytical purposes. This analytical ability provides the robot with a computational mechanism to reason in human-like manners and analyses of the functioning of observed conditions. This is essential in providing better-informed actions and intelligent analysis. Besides, the physical and software design of the robot and essential concepts in human-robot interaction are covered. Also, five evaluation constructs were chosen to evaluate the capability of our robotbased platform. These constructs are; 1) likeability, 2) perceived intelligence, 3) sociability, 4) social presence, and 5) cognitive load. The overall results from the pilot study support the practical usage of our proposed robotic solution. Recognition-Primed Decision (RPD) model that explains how human make decisions based on prior experience. However, the RPD model does not include necessary training factors in making prime decision. Although, there exist an integrated RPD-SA model known as Integrated Decision-making Model (IDM) that includes training factors from Situation Awareness (SA) model, the training factors were not detailed. Hence, the model could not provide reasoning capability. Therefore, this study enhanced the IDM by proposing Computational-Rabiâ€™s Driver Training (C-RDT) model that includes improvement on RPD component of the IDM. The C-RDT includes 18 additional training factors obtained from cognitive theories that make a total of 24 training factors that facilitate driverâ€™s prime decision-making during emergencies. The designed model is realized by identifying factors for prime decision-making in driving domain, designing the conceptual model of the RDT model and formalizing it using differential equation. To demonstrate the designed model, simulation scenarios based on driverâ€™s training and awareness has been implemented. The simulation results are found to support related concepts found in literature. The results also provide insight into the robustness nature of the model. The computational model realized in this study practically can serve as a guideline for software developers on the development of driving assistance systems for prime decision-making process. Also, the computational model when combined with support components can serve as an intelligent artefact for driverâ€™s assistance system. Moreover, the C-RDT model offers reasoning ability that allows backtracking on why certain prime-decision has been made.'),(48,'Abas, Azizi','https://www.scopus.com/authid/detail.uri?authorId=55676845500','Advertisement on products or services can be found in many forms; video, banners, pamphlets, etc. However, these advertisements only function as a one-way communication as consumers are only presented with the product information and the seller. Further action on purchasing the product is absent or is to be made separately. Such an approach may not guarantee a sale for the seller as the customer may only retrieve the information of the product but purchase it elsewhere. Hence, this study demonstrates the use of QR code technology not only in marketing but also in e-commerce. The technology is realized in â€œOn the GoShopâ€‌ mobile application that has two types of users: seller and buyer. Sellers are people who wanted to promote their product and/or services while buyers are the ones who have a desire to purchase. An evaluation study on the acceptance of the mobile application was then performed on a total of 50 respondents and it is learned that the proposed e-commerce application is well accepted. Ninety percent of the respondents agree with the usefulness of the application and are looking forward to using the application in daily routines. The use of QR code technology not only facilitates consumer in purchasing their desired product but also contribute to cost-effective marketing. The design of next Vehicular Ad-hoc Network (VANET) in various technologies will offer seamless connectivity across different coverage. However, VANETâ€™s vertical handover (VHO) decision in seamless connectivity is a huge challenge caused by the network topology complexity. Furthermore, the conventional scheme only uses a received signal strength as a metric value, which shows a lack of appropriate handover metrics that is more suitable in horizontal handover compared to VHO. This study aims to design an intelligent network to minimize the handover delay and latency, and packet loss in the heterogeneous Vehicle-to-Infrastructure (V2I) wireless networks. The proposed intelligent-based scheme uses Fuzzy Logic (FL) that generates multiple attributes parameters using the information context of vertical handover decision in the V2I heterogeneous wireless networks. This study uses a network simulator as the mobility traffic network and vehicular mobility traffic generator to perform a topology in a realistic VANET mobility scenario via Wi-Fi, WiMAX, and LTE networks technologies. The proposed intelligent scheme shows an improvement in the QoS handover over the conventional (RSS-based) scheme with an average QoS increased of 21%, 20%, and 13% in delay, latency and packet loss, while Media Independent Handover based (MIH-based) scheme with 12.2%, 11%, and 7% respectively. The proposed scheme assists the mobile user enhanced the QoS handover during the vehiclesâ€™ movement without degrading the performance of ongoing applications.'),(49,'Harun, Hazaruddin Ezzat','https://www.scopus.com/authid/detail.uri?authorId=41761717200','Leukemia is a type of cancer that affects the white blood cell. Early detection of leukemia is important to reduce the rate of mortality. In order to detect acute leukemia, conventional screening method based on microscopic image is used, where sample of blood cell will be taken from the suspected leukemia patient and manually white blood cell (WBC) condition is observed using microscope. The manual screening process is tedious, time consuming and usually prone to error due to low contrast between the nucleus and cytoplasm of WBCs. This report introduces a new enhancement method which is a combination of Particle swarm optimization (PSO) algorithm and contrast stretching, known as Hybrid PSO-Contrast stretching (HPSO-CS). The PSO has been used to optimize the fitness criterion in order to improve the contrast and detail in microscopic image by adapting the parameters as a contribution to enhancement technique. In this study, PSO algorithm is used to perform image segmentation to remove all the unwanted part such as red blood cell (RBC), platelet and also the background while retain the WBC part. The segmentation algorithm uses saturation S-component based on Hue, Saturation, Intensity (HSI) color model. After the segmentation is done, contrast stretching process is applied to the original image to stretch intensity of the pixel. Then the segmented image is combined with the resultant image that has been stretched to produce the enhanced image. The results of the proposed method are evaluated by using mean-square error (MSE), Peak-signal-to-noise-ratio (PSNR) and Absolute mean brightness error (AMBE). This proposed method is benchmarked by comparing against two image enhancement methods, global enhancement and Class Limited Adaptive Histogram Equalization (CLAHE). Based on the results, it can be concluded that quality of the enhanced image for the proposed method is much better with the lowest MSE (2067.651), AMBE (43.51827) and highest PSNR (14.98671) compared to the global and CLAHE method. The proposed method can improve the screening process and assist haematologist in leukemia screening and detection by improving the visual appearance of the WBC.'),(50,'Wahid, Juliana','https://www.scopus.com/authid/detail.uri?authorId=55331136400','The purpose of this study is to investigate the quality design criteria for developing a Massive Open Online Course (MOOC). Currently, there are limited studies that highlight the required design criteria for the MOOC programming courses. A descriptive analysis was conducted to examine the characteristics of the three important quality design criteria which are (i) Instructional Design Criteria involving Lecture Organization and Culture; (ii) Technical Criteria involving User Interface, Video Content, Learning and Social Tools, and Learning Analytics; and (iii) E-Assessment. The data were collected from 306 respondents, representing the UUM MOOC students of 2018 class, were further analyzed using the T-Test hypothesis testing to determine whether both the programming and nonprogramming students require the same quality design criteria. The questionnaire used in this study consists of 46 items related to the MOOC quality design criteria that were adapted from previous studies. The results indicate that out of the nine constructs, four have obtained significant differences in the mean scores, namely the Video Content, Instructional Design, Culture, and E-assessment. This signifies that different quality design criteria are needed for both the programming and nonprogramming students. The outcome of this study may assist the developers in designing the MOOC by providing the required criteria according to its importance. The high school timetabling problem (HSTP) is considered as an NP-Complete problem as the optimal solution for it, is still not discovered by any algorithm. Generally, NP-Complete problem was solved firstly by constructing the initial solution, in the construction phase. The initial solution will be improvised in the improvisation phase. KHE is an algorithm that generates initial solution of HSTP. The layer sorting procedure in KHE is based on a certain priority. For every two layers, the layers will be ranked based on the highest value of duration. If both layers have equal value of duration, the layer with the highest value of demand will be at a higher rank. If both layers have equal value of demand. The layer will be arranged according to the index value of the layer. These sorting criteria use the layer properties independently which causes non-good results after the time-assignment phase. Therefore, this study proposed a mathematical model based on the Markov Chain Model for the sorting procedure that combines the layer properties in a formula. The proposed model was executed with 40 datasets of XHSTT2014, and it shows better results on 25 datasets of XHSTT2014 compared to the KHE algorithm. The mathematical model based on Markov Chain proposed in this study is able to improvise the original sorting of KHE.'),(51,'Zaini, Khuzairi Mohd','https://www.scopus.com/authid/detail.uri?authorId=26428625700','The ever-increasing amount of networking data as well as the complexity of telecommunication networks is also increasing, consequently the task of network management and troubleshooting is getting more complicated and difficult. Network troubleshooting is an important process, which has a wide research field. The first step in troubleshooting procedures is to collect information in order to diagnose the problems. Syslog messages, which are sent by almost all network devices, contain a massive amount of data related to the network problems. Detecting network problems could be more efficient if the detected problems have been classified in terms of network layers. In this paper, we focus on the usage of classification technique in the field of network management, more specifically in fault management. This paper proposes a layered based classification framework to classify syslog messages that indicates the network problem in terms of network layers. The method used data mining tool to classify the syslog messages, while the description part of the syslog message was used for classification process. Related syslog messages were identified; features were then selected to train the classifiers. Data Grid is an infrastructure that manages huge amount of data files, and provides intensive computational resources across geographically distributed collaboration. Increasing the performance of such system can be achieved by improving the overall resource usage, which includes network and storage resources. Improving network resource usage is achieved by good utilization of network bandwidth that is considered as an important factor affecting job execution time. Meanwhile, improving storage resource usage is achieved by good utilization of storage space usage. Data replication is one of the methods used to improve the performance of data access in distributed systems by replicating multiple copies of data files in the distributed sites. Having distributed the replicas to various locations, they need to be monitored. As a result of dynamic changes in the data grid environment, some of the replicas need to be relocated. In this paper we proposed a maintenance replica placement strategy termed as Unwanted Replica Deletion Strategy (URDS) as a part of Replica maintenance service. The main purpose of the proposed strategy is to find the placement of unwanted replicas to be deleted. OptorSim is used to evaluate the performance of the proposed strategy. The simulation results show that URDS requires less execution time and consumes less network usage and has a best utilization of storage space usage compared to existing approaches. WLAN has been considered as a compliment technology for cellular network in the heterogeneous wireless network. Thus, seamless connection between these technologies play important role as the performance indicator. In this paper, we consider the user\'s velocity and channel holding time to predict the user\'s dwelling time in the WLAN area to assist in the initial network selection. If the expected completion time is lower than the predictive travelling time within the coverage area, together with the load and service characteristics, the algorithm will select WLAN instead of cellular network. Based on the discrete-event simulation, the results show that the proposed solution has better performance as compared to the location-based (WLAN First) and mobility threshold proposals.'),(52,'Md. Rejab, Mawarny','https://www.scopus.com/authid/detail.uri?authorId=56286310600','Given the possibilities of smart cities to significantly affect human lives, issues related to security have come into a spotlight to public and industries. People are now connected to each other through smart telephones and other gadgets. Facilities like smart meters, security gadgets and smart machines are being utilized in numerous cities. This study presents the security measures in the context of smart city advancement. Security matters in this context encompasses unlawful access to information and attacks causing physical disturbances in administration accessibility. Semi-structured interviews on 30 government officials, policymakers and regulators were applied to saturate categories. The outcome uncovered a dimension of \'evolving security\' as having positive effect and prompts how King Hussein Business Park (KHBP) is a mix for planning a robust security initiative for the securing of a smart city. City foundations and administrations are now evolving and experiencing changes amidst new interrelated systems for monitoring, control, and automation. Smart transportation, open and private, will get to a snare of interrelated information from GPS area to weather and traffic updates. Integrated systems will help open wellbeing, emergency responders and in misfortune recuperation. Nowadays, software development failure has become a very serious problem. Inaccurate time estimation is one of the major causes of the software development failure. Inaccurate time estimation mostly creates time pressure that causes several negative impacts on software developersâ€™ mental and physical health. The past studies had also believed that burnouts and job turnover problems happened due to time pressure. Therefore, the objective of this study is to explore time pressure with human behavior to see if they can make any relation. By this way, one can explore the hidden patterns between time pressure and human behavior in software engineering. In order to carry out the study, personality and time pressure studies are explored in general to see if past studies had ever made any space for software domain. Moreover, based on the limited selected studies, the literature review identifies that several authors had correlated the time pressure with personality. Unfortunately, time pressure and software developer personality are not specifically studied together in software engineering. For that reason, this study leaves some recommendations for researchers to contribute in the very topic to make software development better. '),(53,'Mohsin, Mohamad Farhan Mohamad','https://www.scopus.com/authid/detail.uri?authorId=25825198500','Multi-label classification is a general type of classification that has attracted many researchers in the last two decades due to its applicability to many modern domains, such as scene classification, bioinformatics and text classification, among others. This type of classification allows instances to be associated with more than one class label at the same time. Class label ranking is a crucial problem in multi-label classification research, because it directly impacts the performance of the final classifiers, as labels with high ranks get a higher chance of being applied. This paper presents a new multi-label ranking algorithm called Multi-label Ranking based on Positive Correlations among labels (MLR-PC). MLR-PC captures positive correlations among labels to reduce the large search space and assigns the true rank per class label for multi-label classification problems. More importantly, MLR-PC utilizes novel problem transformation methods that facilitate exploiting accurate positive correlations among labels. This improves the predictive performance of the classification models derived. Empirical results using different multi-label datasets and five evaluation metrics reveal that the MLR-PC is superior to other commonly existing classification algorithms. The purpose of this study is to enhance the exploration capability of conventional Salp Swarm Algorithm (SSA) with the inducing of Levy Flight. With such modification, it will assist the SSA from trapping in local optimum. The proposed approach, which is later known as an improved SSA (iSSA) is employed in monthly dengue outbreak prediction. For that matter, monthly dataset of rainfall, humidity, temperature and number of dengue cases were employed, which render prediction information. The efficiency of the proposed algorithm is evaluated using Root Mean Square Error (RMSE), and compared against the conventional SSA and Ant Colony Optimization (ACO). The obtained results suggested that the iSSA was not only able to produce lower RMSE, but also capable to converge faster at lower rate as well. Multi-Label Classification (MLC) is a general type of classification that has attracted many researchers in the last few years. Two common approaches are being used to solve the problem of MLC: Problem Transformation Methods (PTMs) and Algorithm Adaptation Methods (AAMs). This Paper is more interested in the first approach; since it is more general and applicable to any domain. In specific, this paper aims to meet two objectives. The first objective is to propose a new multi-label ranking algorithm based on the positive pairwise correlations among labels, while the second objective aims to propose new simple PTMs that are based on labels correlations, and not based on labels frequency as in conventional PTMs. Experiments showed that the proposed algorithm overcomes the existing methods and algorithms on all evaluation metrics that have been used in the experiments. Also, the proposed PTMs show a superior performance when compared with the existing PTMs.'),(54,'Awang Nor, Shahrudin','https://www.scopus.com/authid/detail.uri?authorId=26428351800','The wide applicability of Software-defined networking (SDN) technology has made it a better choice over all other architectures of the Future Internet, such as Information-centric networking (ICN) and Named Data Networking (NDN). Recent advances in this technology have increased its usability in simplifying the management of various types of networks such as data-center network, enterprises, wireless and campus networks. SDN is an emerging norm of programming networks paradigm. In this fashion, SDN separates and centralizes the control logic from the network forwarding devices. This decoupling provides the capability for programming the network and promotes the logical centralization of network control. Thus, this separation provides higher flexibility to accommodate innovative network designs and allows faster innovation in both control plane and data plane. Hence, this study focused on SDN and OpenFlow technologies. It presents a brief introduction of the current network architecture, followed by an in-depth discussion of the basic architecture of both SDN and OpenFlow and its evolutions. The study concludes by discussing the research challenges and future directions to provide future researcher\'s a brief insight into the future scope in this area. The tremendous growth of todayâ€™s Internet traffic has launched new challenges in present IP Internet architecture. Similar content called again and again that creates a large amount of Internet traffic. There is a need to implement an efficient architecture to handle this problem. It is necessary to reduce the content redundancy to make Internet architecture efficient. Now the new research is introducing about the converting of IP host-based architecture Information-based. The Internet tradition has changed from IP to content dissemination. Host-to-host infrastructures tend to vanish to construct way for one-to-many or many-to-many sharing and reclamation of information objects with a growing request for an enhanced network design. Clients just desire to know about the contentâ€™s availability and how can get it quickly where they wished as well as do not care about the physical location. While inventive solutions have proposed successfully and proved to address new Internet paradigm and these solutions provide a lot of benefits in terms of security, mobility, scalability and manageability. '),(55,'Hassan, Syahida','https://www.scopus.com/authid/detail.uri?authorId=56069848900','The purpose of this study is to investigate the quality design criteria for developing a Massive Open Online Course (MOOC). Currently, there are limited studies that highlight the required design criteria for the MOOC programming courses. A descriptive analysis was conducted to examine the characteristics of the three important quality design criteria which are (i) Instructional Design Criteria involving Lecture Organization and Culture; (ii) Technical Criteria involving User Interface, Video Content, Learning and Social Tools, and Learning Analytics; and (iii) E-Assessment. The data were collected from 306 respondents, representing the UUM MOOC students of 2018 class, were further analyzed using the T-Test hypothesis testing to determine whether both the programming and nonprogramming students require the same quality design criteria. The questionnaire used in this study consists of 46 items related to the MOOC quality design criteria that were adapted from previous studies. The results indicate that out of the nine constructs, four have obtained significant differences in the mean scores, namely the Video Content, Instructional Design, Culture, and E-assessment. This signifies that different quality design criteria are needed for both the programming and nonprogramming students. The outcome of this study may assist the developers in designing the MOOC by providing the required criteria according to its importance. Social media plays an important role in marketing specifically in digital marketing. Many entrepreneur and businesses start to promote their brand and items on the social media platform such as Instagram. The main objective of this study is to crawl data from Instagram and perform some simple analysis to get some entrepreneurial ideas. A system named Graduate Entrepreneur Opportunity Recognition System (GEORsys) is proposed in this study. Hashtags for custom words or sectors like agriculture, services, food and beverages (F&B), fashion, information, communication and technology (ICT) and logistics are used to crawl data from Instagram. Then, some simple visualizations are shown to conclude what keywords or hashtags are popular in Instagram. Public health, safety and welfare of community is one of the important sustainable development goals. Basic water supply, electricity and waste disposal must be in optimum condition in promoting quality of life. Citizens need to be afforded with simple and usable system for reporting problems related to the public facilities and services to their local councils. Currently, there is no integrated online mechanism for reporting and monitoring the problems. This study proposes a simple and usable mobile application for reporting known as My Response. Additionally, how usability factors are related to intention of using this apps were analyzed. 40 local people participated in the usability study. Usability attributes accommodated in this application such as the instant start or launch feature, well and comprehensible designed icon positively correlates with intention to use the application. The usage of understandable terminology, concise language and minimal user effort required in MyResponse also positively correlates with intention to use. In our study, simplicity and understandability in using and navigating the apps is the golden rule.'),(56,'Saip, Mohamed Ali','https://www.scopus.com/authid/detail.uri?authorId=57192192570','Social media have become an important interaction channel between the government and citizens in the era of the digital community. The adoption of social media in local government services offers a new channel to encourage citizen engagement in the public policy decision-making process. Moreover, communication with citizens through social media exposes large opportunities for the local government to analyse and appreciate the relationships among social media participants in the digital community to enhance public services. The purpose of this study is to understand the local government\'s social media network and identify the social role in the local government\'s social media network structure. Thus, this study adopted the social network analysis (SNA) approach on the Twitter data of a local government\'s official account in the UK as a case study. The study revealed that the internal local government stakeholders play an important social role in the local government\'s social media network. The implication of the study was discussed. This E-Tendering systems remain uncertain on issues relating to legal and security compliance, in which unclear security framework is one of the issues. In te current situation, tendering systems are lacking in addressing integrity, confidentiality, authentication, and non-repudiation. Thus, ensuring the system requirements, consider security and trust issues has to be regarded as one of the challenges in developing an e-Tendering system. Therefore, this paper a model of a secured e-Tendering system using Unified Modeling Language (UML) approach. The modelling process begins with identifying the e-Tendering process, which is based on Australian Standard Code of Tendering (AS 4120-1994). It is followed by identifying the security threats and its countermeasure. The use case approach has been proven reliable in determining appropriate requirements for handling security issues. Having considered that, the outcome of this paper is a secured e-Tendering model. The model can guide developers as well as other researchers. '),(57,'Ani, Zhamri Che','https://www.scopus.com/authid/detail.uri?authorId=54583194600','Mobile governance enables citizens to comfortably do business with government anywhere, any time. This provides an enriching experience to users as they use these platforms in their convenience and with comfort. MyEG Services Berhad (\"MyEG\"\") is a concessionaire for Malaysian Electronic- Government (\"\"E-Government\"\") MSC Flagship Application. MyEG manages the electronic channel that offers services from various Government agencies to the Malaysian citizens and businesses. The MyEG developed a mobile application that can be used to check summons'),(58,'Azzali, Fazli','https://www.scopus.com/authid/detail.uri?authorId=43061094300','The design of next Vehicular Ad-hoc Network (VANET) in various technologies will offer seamless connectivity across different coverage. However, VANETâ€™s vertical handover (VHO) decision in seamless connectivity is a huge challenge caused by the network topology complexity. Furthermore, the conventional scheme only uses a received signal strength as a metric value, which shows a lack of appropriate handover metrics that is more suitable in horizontal handover compared to VHO. This study aims to design an intelligent network to minimize the handover delay and latency, and packet loss in the heterogeneous Vehicle-to-Infrastructure (V2I) wireless networks. The proposed intelligent-based scheme uses Fuzzy Logic (FL) that generates multiple attributes parameters using the information context of vertical handover decision in the V2I heterogeneous wireless networks. This study uses a network simulator as the mobility traffic network and vehicular mobility traffic generator to perform a topology in a realistic VANET mobility scenario via Wi-Fi, WiMAX, and LTE networks technologies. The proposed intelligent scheme shows an improvement in the QoS handover over the conventional (RSS-based) scheme with an average QoS increased of 21%, 20%, and 13% in delay, latency and packet loss, while Media Independent Handover based (MIH-based) scheme with 12.2%, 11%, and 7% respectively. The proposed scheme assists the mobile user enhanced the QoS handover during the vehiclesâ€™ movement without degrading the performance of ongoing applications. The design of next generation networks in various technologies under the \"Anywhere'),(59,'Sajat, Mohd Samsu Bin','https://www.scopus.com/authid/detail.uri?authorId=35198969900','Grid Computing is a set of resources; the separate computational power of these resources has combination to execute a huge task. Usually, in a Computational Grid environment, the main resource is the Central Processing Unit (CPU), mostly used in research fields that demand high computational power to perform massive and complicated calculations. Cloud Computing is a promising computing pattern which offers facilities and common resources on demand over the Web. The implementation of cloud computing applications has high priority, especially in the modern world, for example in providing adequate funding for social services and purchasing programs. In this paper, we discuss the implementation of cloud computing over a Smart Grid: reliable, guaranteed and efficient with low cost, it is expected to offer Long Term Evolution (LTE). This allows larger pieces of the spectrum, or bands, to be used, with greater coverage and less latency. The third technology is the Vehicular Network, an important research area because of its unique features and potential applications. In this survey, we present an overview of the smart grid, LTE and vehicular network integrated with cloud computing. We also highlight the open issues and research directions in implementing these technologies with cloud computing in terms of energy and information management for smart grids; applying cloud computing platforms for 4G networks to achieve specific criteria; and finally architectural formation, privacy and security for vehicular cloud computing. Mode division multiplexing (MDM) has emerged as a new multiplexing paradigm for enhancing the bandwidth by leveraging the orthogonal modes as a parallel channel for transferring information. Although capacity gains theoretically increase in relation to the number of modes in MDM, mode coupling inevitably causes modes to interchange power randomly, leading to channel degradation from different arrival mode delay and inter-symbol interference (ISI). Hence, this paper demonstrates a new neural network feed-forward and back propagation equalizer to mitigate pulse broadening caused by mode-coupling.'),(60,'Husin, Mohd Zabidin','https://www.scopus.com/authid/detail.uri?authorId=57199718183','Question answering system (QAS) is an example of an application of natural language processing where it is able to automatically return a specific answer to a question given in a natural language by a human. One of the important tasks in QAS is Question Classification which is the task to identify the semantic type of the required answer for the question posed to the QAS. Identifying the correct answer type is an important process before the required correct answer can be retrieved by the system. In this paper we presents a model of Answer Type Classification using machine learning approach targeted for a Malay QAS for the Quran, which is a restricted-domain QAS. The performance of the classification model using three different machine learning classification algorithms, namely Naأ¯ve Bayes, Random Forest and Support Vector Machine (SVM), are then evaluated. The results show that the classifier based on SVM has the best overall results in terms of accuracy, precision, recall and F1-score. Concept extraction is one of the important parts in ontology learning approach in order to construct ontology. This step becomes an inevitable process in such ontology development and becomes a seed to the next step in the approach. Studies in unstructured text especially in Malay are quite little due to the lack of availability extraction tools to extract relevant information. In addition, studies in Malay unstructured text based on Al-Quran is very rare compared to English and Arabic text. In this paper, an early experiment was carried out to extract concepts from Malay translation of Quranic texts using several rules-based formulated by Malaysian government body that responsible for Malay language. The study focuses only noun phrases in the Malay Quranic Text which involves only twenty- two short chapters or surah that comprises from Surah Ad-Dhuha to An-Nas. There are two criteria that have been tested in terms of symbols and stop words. The result of noun phrases has been extracted range from a combination of one word to twelve words. It shows that all the extracted noun phrases are not sufficient enough to extract most of the important concept in Al-Quran.'),(61,'ChePa, Noraziah C.','https://www.scopus.com/authid/detail.uri?authorId=56951111900','Focusing on validating on how game rewards can positively improve motivation towards games engagement, this paper present how rewards have been incorporated in two digital traditional games. Congkak and Snakes and Ladder games are chosen to be enhanced with rewards due to its popularity. Study started by analysing and designing how rewards are incorporated in the chosen games. Credits point is chosen to be rewarded to players who win and solved problems in the game. Validation process involved series of experiments which include game demos, game experience, and systematic interview. Findings revealed how players responded positively to rewards when they demonstrate how they attracted, hooked and endured the games. The injection of rewards in Digital Traditional Games is believed to be useful to new psychologists to obtain more understanding pertaining to games engagement through some experiments of rewards in traditional games. Games have been widely used in many domains including medical for therapy purposes. With the advancement of technology, mobile psychotherapy games have essential role in improving memory among elderly patients. There are numbers of psychotherapy games that have been developed for elderly with memory disorder. However, at one point most of the developed games are still questionable since there is lack of game development guides for this particular purpose. Designing the optimum design for the psychotherapy games, which emphasizes the users in it will be able to maximise the effectiveness of the games. Thus, this study aims to review the literatures systematically in identifying the criteria for mobile psychotherapy games specifically for memory disorder. To achieve this, three databases were used in searching literatures which are Scopus, Web of Science and ACM Digital Library. The search identified 992 articles altogether;69 papers remains for further selection process while 909 were excluded due to irrelevancy of the focus. The selection process later refrained to 16 articles being analysed and synthesised. The selection incorporated all articles which focused directly on the psychotherapy games for memory disorder elderly patients concentrated on mobile devices. As a result, a set of important criteria for different themes on designing mobile psychotherapy game has been identified. Significant features of psychotherapy games were found in majority of the reviewed articles. These criteria will be beneficial in forming a guideline for designing and developing mobile psychotherapy games for memory disorder patients.'),(62,'Abu Bakar, Nur Azzah','https://www.scopus.com/authid/detail.uri?authorId=35067833100','Blockchain technology and cryptocurrency are attracting increasing attention from consumers, investors, investment industry and regulators. Cryptocurrency has great potential to be used for transaction or investment in the future. However, level of awareness of the blockchain technology and cryptocurrency is still at infant stage, specifically in developing countries. Thus, this study aims to investigate the level of awareness, trust and adoption of blockchain technology among blockchain community in Malaysia. Quantitative approach was adopted in this study where a new questionnaire was developed in the first phase to measure the level of awareness, adoption, and trust of blockchain technology applications among Malaysian blockchain communities. The resulting questionnaire consists of items on respondents\' demographic, their awareness, trust, and adoption of FinTech particularly on blockchain technology and cryptocurrency. In the second phase, a pilot study was conducted to validated the new questionnaire from 304 respondents. Reliability test using Cronbach\'s alpha with a value of 0.908. A real survey was also conducted in this phase using the validated queationnaire and data were obtained online from 304 respondents. Descriptive statistics were used in the analysis during the third phase of the study, and results demonstrate that the awareness level of blockchain technology and cryptocurrency are at the intermediate level. Nevertheless, the majority of respondents are confident and trust that the blockchain technology can offer a stable and secure platform, which gives positive impact on the application of the technology. Empirical results provide significant insights into the development of the blockchain technology industry in the country. Successful implementation of Information System (IS) in government hospitals is indeed a challenging task. Fail to prevent or control challenges of Information System (IS) implementation have led to the failure of its implementation. Government has invested a big amount of money on information system (IS) projects to improve service delivery in healthcare. However, several of them failed to be implemented successfully due to several factors. This article proposes how Change Management (CM) helps in preventing the failure of IS implementation, hence ensuring the success of it. This study starts by discovering challenges of IS implementation in government hospitals. Combination of extensive literature review and deep interview approaches were employed to discover these challenges. CM has been employed in designing a prevention model to cater the challenges. The model caters three main phases of implementation; pre-implementation, during implementation, and post-implementation by adopting CM practices of Lewin\'s, Kotter\'s and Prosci\'s CM model. Six elements of CM comprising thirteen sub-elements adopted from the three CM models have been used to handle CFFs of Human and Support issues; guiding team, resistance avoidance, IS adoption, enforcement, monitoring, and IS sustainability. Successful practice of the proposed mapping is expected to prevent CFFs to occur, hence ensuring a successful implementation of IS in the hospitals. The proposed model has been presented and successfully evaluated by the domain experts from the selected hospitals. The proposed model is believed to be beneficial for top management, IT practitioners and medical practitioners in preventing IS implementation failure among government hospitals towards ensuring the success implementation.'),(63,'Puteh, Nurnasran','https://www.scopus.com/authid/detail.uri?authorId=42962245800','Technology has changed the way we work. These have increased the productivity in the workplace. The purpose of having a conference paper app is to aid researcher to improve the effectiveness and efficiency of management of conference paper. Without a proper management of these substances, people might suffer from the inconvenience by using a desktop system to complete certain tasks and monitor them efficiently. However, based on investigating the existing applications, a few shortcomings have been identified. Certain shortcoming leads us to develop a new mobile application to fix the identified shortcomings. Some others include complex navigation of user interfaces, this cause a poor user experience for users. Hence, this project proposes a development of a mobile application that is called CPMA, which serve as a better alternative tool to allow users managing and monitoring information related to conference paper in a more efficient way. This app specifically developed for researchers in higher learning institutions who are needed to proceed with conference paper. Software development methodology named prototyping will be adopted, which consisted of phases such as planning, repeated phases (analysis, design, implementation and system prototype), implementation and final system. The essential significance of this project is to provide a platform for researcher to manage and monitor conference paper in a savvy manner. By the time of completing this project, users are expected to access this application without any costs and increase the efficiency and effectiveness of managing conference paper. To ensure the security is presented in a tabular form for each online marketplace. Question answering system (QAS) is an example of an application of natural language processing where it is able to automatically return a specific answer to a question given in a natural language by a human. One of the important tasks in QAS is Question Classification which is the task to identify the semantic type of the required answer for the question posed to the QAS. Identifying the correct answer type is an important process before the required correct answer can be retrieved by the system. In this paper we presents a model of Answer Type Classification using machine learning approach targeted for a Malay QAS for the Quran, which is a restricted-domain QAS. The performance of the classification model using three different machine learning classification algorithms, namely Naأ¯ve Bayes, Random Forest and Support Vector Machine (SVM), are then evaluated. The results show that the classifier based on SVM has the best overall results in terms of accuracy, precision, recall and F1-score.'),(64,'Razak, Rafidah Abd','https://www.scopus.com/authid/detail.uri?authorId=23390337100','This paper presents countriesâ€™ analysis in online Services Index performance (OSI) ranking to improve Malaysia UN ranking. The study found that the top 5 countries (Spain, Saudi Arabia, Slovenia, Malta, Serbia and UAE)by-passed Malaysia the most out of 35 countries in the last 10 years. This study proposed future research to find gaps and areas for improvement while gaining insights from international best practices that have enabled other governments to surge ahead. In particular, the study found how Malaysia can improve UN ranking through investigating what those countries that by-passed Malaysia the most in the last 10 years are doing that have enabled them to offer much superior e-Government services. The online services index is one of three components of the United Nations e-government development index. It attempts to capture a country\'s performance in a single internationally-comparable value using a four-stage model of online service maturity. The summary of selected countries that had overtaken Malaysia in the past 10 years had been analyst. These countries (UAE, Serbia, Malta, Spain and Saudi Arabia) have the most drastic changes to their online services that overtook Malaysia in the last 10 years. This study had found gaps and areas for improvement while gaining insights from international best practices that have enabled other governments to surge ahead. The result shows that multiple languages, transaction, social media Tools, Link to Ministries, download document, facilities to check insurances coverage, single citizen log in before accessing facilities by ministry, notification of official event/new thru text and video, display statistics for visitor, provide ebook reader, display map of ministry office for visitor point of reference, provide opinion by citizen to different ministry, provide e-participation, place to display ministry publication list, smart phone application and follow up application electronically were found to effect OSI performance these five countries. '),(65,'Wan Ishak, Wan Hussain','https://www.scopus.com/authid/detail.uri?authorId=35174468600','Finding information from a large collection of resources is a tedious and time-consuming process. Due to information overload, searchers often need help and assistance to search and find the information. Recommender system is one of the innovative solutions to the problem related to information searching and retrieval. It helps and assist searchers by recommending the possible solution based on the previous search activities. These activities can be obtained from the web log, which requires a web log mining approach to extract all the keywords. In this study, keywords obtained from the library web log were analysed and the search keyword patterns were obtained. These keyword patterns were from several databases or resources that were subscribed by the library. The finding revealed some of the popular keywords and the most searchable databases among the searchers. This information was used to design and develop the recommender system that can be used to assist other searchers. The usability test of the recommender system showed that it is beneficial and useful to the searchers. These findings will also benefit the management in planning and managing the subscription of online databases at the universityâ€™s library. A huge variety of software systems are relied upon in such domains as aviation, healthcare, manufacturing and robotics, and therefore, h systems and that they are reliable. Software defect prediction helps improve software reliability by identifying potential bugs during software maintenance. Traditionally, the focus of software defect prediction was on the design of static code metrics, which help with predicting the defect probabilities of a code when input into machine learning classifiers. While machine learning techniques such as Deep Learning technique, Ensembling, Data Mining, Clustering and Classification are known to help predict the location of defects in code bases, researchers have not yet agreed on which is the best predictor model. This paper will use 13 software defect datasets in evaluating the performance of the different predictor models. The results show that consistency in high accuracy prediction was achieved using Ensembling techniques. The task of the planning phase prior to travelling is always undervalued as an effort that takes time to create and manage. Finding locations that are good to visit is hard as people do not always know whether what they are reading is true or whether it is forged to give the impression that it is good when it is actually not. Research regarding the process of searching for information about locations does not receive considerate attention from researchers, resulting in limited studies about the topic in the literature. Therefore, this study aimed at bridging the gap by designing and developing a web app (application) for sharing information of interesting locations. The evolutionary prototyping methodology was adopted in designing and developing the prototype. The prototype named Collaborative Information Sharing System (CISS) was developed based on the gathered requirements. The results of the evaluation suggested that CISS is indeed useful and easy to use. The study contributes towards the understanding of the system requirements and user interface of a web application for sharing information of interesting locations.'),(66,'Darus, Norida Muhd','https://www.scopus.com/authid/detail.uri?authorId=54583376900','Recently, business transformation towards the used of Information and Communication Technology (ICT) is a necessity toward rapid industries and the paradigm shifted to sustain business competitiveness. The holistic electronic approach is one of business innovations, especially in handling a lot of tender documentations and process in an electronic environment namely as e-Tendering. Unfortunately, the existing tender process transformation in the electronic approach is not properly followed certain standard and guideline, especially in establishing a good e-Tendering functional requirements specification to ensure the organizations would be in the best served. This is important to ensure a good e-Tendering system can be developed by e-Tendering developers based on a good e-Tendering functional requirement specifications. The requirements specification is a process of documenting user and system requirements. Commonly, user and system requirements should be clear, unambiguous, easy to understand, complete, and consistent. In practice, this is difficult to achieve due to interpretation of the requirements in different ways by stakeholders, which are often inherent conflicts and inconsistencies of the requirements. The implementation of the existing e-tendering still remains uncertainties, especially in defining the functional requirements of the e-tendering system. Therefore, this study aims to construct the e-Tendering functional requirement model using requirement template in natural language representation approach. Moreover the development of this system requirement model may provide a consistency to the requirements representation. The study uses UN/CEFACT Business Standard of the e-Tendering Business. The identified functional requirements are designed by using Requirement Template to ensure the reliability and understandability of requirements. Besides, the proposed functional requirements is constructed by adapting the natural language and verified by expert review approaches. As a result, this study proposed a functional requirements specification of the e-Tendering that contains detailed description which can be referred by software practitioners in developing a secure e-tendering system effectively. This E-Tendering systems remain uncertain on issues relating to legal and security compliance, in which unclear security framework is one of the issues. In te current situation, tendering systems are lacking in addressing integrity, confidentiality, authentication, and non-repudiation. Thus, ensuring the system requirements, consider security and trust issues has to be regarded as one of the challenges in developing an e-Tendering system. Therefore, this paper a model of a secured e-Tendering system using Unified Modeling Language (UML) approach. The modelling process begins with identifying the e-Tendering process, which is based on Australian Standard Code of Tendering (AS 4120-1994). It is followed by identifying the security threats and its countermeasure. The use case approach has been proven reliable in determining appropriate requirements for handling security issues. Having considered that, the outcome of this paper is a secured e-Tendering model. The model can guide developers as well as other researchers.');
/*!40000 ALTER TABLE `user_1` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2022-03-20 17:06:38
